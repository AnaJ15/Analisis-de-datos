{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esquema para una Super-Plantilla DW (Ultra-bright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pylab (from versions: none)\n",
      "ERROR: No matching distribution found for pylab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: chardet in c:\\programdata\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib\n",
    "! pip install seaborn\n",
    "! pip install pylab\n",
    "! pip install scipy\n",
    "! pip install chardet\n",
    "! pip install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero los que sean de python (core)\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "# después lo de terceros\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "import chardet\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "\n",
    "# por último los nuestros (si los hay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Instalar las librerías faltantes si falla la carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !pip install chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020_Accidentalidad.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('2020_Accidentalidad.csv', encoding='latin1', on_bad_lines='skip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Si falla la carga, utilizar chardet para la codificación correcta del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo=\"./carpeta/2020_Accidentalidad.csv\"\n",
    "separador=\";\"\n",
    "\n",
    "def pd_abrir_archivo(ruta_archivo, separador=','):\n",
    "    with open(ruta_archivo, 'rb') as original:\n",
    "        resultado = chardet.detect(original.read())\n",
    "    return pd.read_csv(ruta_archivo, sep=separador, encoding=resultado['encoding'])\n",
    "\n",
    "df = pd_abrir_archivo(ruta_archivo, separador)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 En caso de tener muchos ficheros a cargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pathlib\\ndirectorio = pathlib.Path(\\'./carpeta/coches/\\')\\nprint(\"Trabajando con los ficheros del directorio: ./\"+str(directorio))\\nprint(\"===========================================\")\\ndatos = []\\nfor fichero in list(directorio.glob(\\'*.csv\\')):\\n    # procesamiento de cada fichero\\n    # y ahora podremos cargarlo\\n    print(fichero)\\n    df = pd.read_csv(fichero, sep = \\',\\')\\n    datos.append(df)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pathlib\n",
    "directorio = pathlib.Path('./carpeta/coches/')\n",
    "print(\"Trabajando con los ficheros del directorio: ./\"+str(directorio))\n",
    "print(\"===========================================\")\n",
    "datos = []\n",
    "for fichero in list(directorio.glob('*.csv')):\n",
    "    # procesamiento de cada fichero\n",
    "    # y ahora podremos cargarlo\n",
    "    print(fichero)\n",
    "    df = pd.read_csv(fichero, sep = ',')\n",
    "    datos.append(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Realizar el EDA automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Pandas-Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas-profiling in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (3.2.0)\n",
      "Requirement already satisfied: joblib~=1.1.0 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (1.11.4)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (2.1.4)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (3.8.0)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (1.10.12)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (6.0.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (2.1.3)\n",
      "Requirement already satisfied: visions==0.7.4 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (1.26.4)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (0.1.12)\n",
      "Requirement already satisfied: missingno>=0.4.2 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (0.5.2)\n",
      "Requirement already satisfied: phik>=0.11.1 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (0.12.4)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.2.0 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (4.65.0)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (0.12.2)\n",
      "Requirement already satisfied: multimethod>=1.4 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (1.12)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from visions==0.7.4->visions[type_image_path]==0.7.4->pandas-profiling) (23.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from visions==0.7.4->visions[type_image_path]==0.7.4->pandas-profiling) (3.1)\n",
      "Requirement already satisfied: imagehash in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (4.3.1)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (10.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic>=1.8.1->pandas-profiling) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.48.2->pandas-profiling) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.0->pandas-profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\programdata\\anaconda3\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling) (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numba in c:\\programdata\\anaconda3\\lib\\site-packages (0.59.0)\n",
      "Collecting numba\n",
      "  Downloading numba-0.60.0-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: pandas-profiling in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (3.2.0)\n",
      "Requirement already satisfied: visions in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (0.7.4)\n",
      "Collecting visions\n",
      "  Downloading visions-0.7.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba) (1.26.4)\n",
      "Requirement already satisfied: joblib~=1.1.0 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (1.11.4)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (2.1.4)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (3.8.0)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (1.10.12)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (6.0.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (2.1.3)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (0.1.12)\n",
      "Requirement already satisfied: missingno>=0.4.2 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (0.5.2)\n",
      "Requirement already satisfied: phik>=0.11.1 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (0.12.4)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.2.0 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (4.65.0)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling) (0.12.2)\n",
      "Requirement already satisfied: multimethod>=1.4 in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from pandas-profiling) (1.12)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from visions) (23.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from visions) (3.1)\n",
      "Requirement already satisfied: imagehash in c:\\users\\ana.jimeno\\appdata\\roaming\\python\\python311\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (4.3.1)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (10.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic>=1.8.1->pandas-profiling) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.48.2->pandas-profiling) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.0->pandas-profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\programdata\\anaconda3\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling) (1.5.0)\n",
      "Downloading numba-0.60.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.7/2.7 MB 23.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.9/2.7 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 21.4 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.9/28.1 MB 19.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.6/28.1 MB 33.0 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 5.2/28.1 MB 37.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 6.5/28.1 MB 34.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 8.1/28.1 MB 34.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 10.0/28.1 MB 35.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 12.1/28.1 MB 40.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 14.1/28.1 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 16.1/28.1 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 18.0/28.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 20.1/28.1 MB 43.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.9/28.1 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.8/28.1 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 38.5 MB/s eta 0:00:00\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.43.0 numba-0.60.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numba pandas-profiling visions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numba==0.56.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade numba visions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall pandas-profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numba==0.56.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# Crear el perfil del informe\n",
    "prof = ProfileReport(df)\n",
    "\n",
    "# Guardar el informe en un archivo HTML\n",
    "nombre = input(\"¿Cómo llamo al informe? \") + '.html'\n",
    "prof.to_file(nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. DTale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtale\n",
    "\n",
    "dtale.show(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. MiQueridoEDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### Primera hipótesis  ####\n",
    "###########################\n",
    "\n",
    "# Este sitio está reservado a instrucciones que nos va dar información propia de un EDA\n",
    "\n",
    "# Hay que sacar los datos de numero de accidentes por expendiente (Group by)\n",
    "\n",
    "# Habia que agrupar las fechas y horas conociendo si es festivo, si es hora punta, etc\n",
    "\n",
    "# CALLE 7622 distintos, \n",
    "# 1. Buscar en internet si tenemos información de puntos negros en la capital para resolver la \n",
    "# alta cardinalidad de Calle y numero\n",
    "# 2. Asociar un numero entero en relacion a la media de lesividad que tiene (ordenandolo) (sospechoso)\n",
    "# 3. Dummies o Hot encoding (7622 columnas) no hay problema con aprendizaje espúreo pero sin con\n",
    "#   baja varianza.\n",
    "\n",
    "# El campo estado meteorologico tiene desprocionado el valor DESPEJADO.\n",
    "# 10% nulos\n",
    "# 1. Realizar algún subprograma que pida al api de AEMET que tiempo hacía realmente ese día y a esa hora\n",
    "# 2. No hago nada y agrupo en DESPEJADO y NO DESPEJADO\n",
    "# 3. Tomo muchas menos filas de DESPEJADO en el ENTRENAMIENTO   ---> descartada por pocas filas\n",
    "\n",
    "# Tipo vehiculo tiene descompensación de resultados.\n",
    "# 1. Poner los datos en relación con el total de vehículos en Com. Madrid matriculados (DGT)\n",
    "# 2. Nada, agrupo por Turismos y No Turismos\n",
    "\n",
    "# Tipo persona también tiene descompensacion\n",
    "# 1. Agrupo en Conductores o No conductores\n",
    "# 2. Solo son tres categorias me arriesgo a que falle cuando sea Peaton y Pasajero\n",
    "# 3. No agrupo nada. y De manera artificial en el entrenamiento tomar menos filas del \n",
    "#    total de conductor ------> descartada por pocas filas\n",
    "\n",
    "# Tipo accidente agruparemos a partir de 4% (otros)\n",
    "\n",
    "# Rango de edad agruparemos a partir del 3% (otros)\n",
    "\n",
    "# Campo sexo tiene muchos nulos 11%\n",
    "\n",
    "# TARGET: Lesividad tiene  muchos nulos pero se pueden convertir a la categoria 14. 74% de ilesos\n",
    "# No es float es categórica, no está graduada.   \n",
    "# Tendremos que tener cuidado con la metrica de evaluacion a elegir\n",
    "\n",
    "# Unnamed: 13 y Unnamed: 14 a la basura\n",
    "\n",
    "# Fila duplicadas 5% \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32420 entries, 0 to 32419\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   NEXPEDIENTE     32420 non-null  object \n",
      " 1   FECHA           32420 non-null  object \n",
      " 2   HORA            32420 non-null  object \n",
      " 3   CALLE           32420 non-null  object \n",
      " 4   NUMERO          32418 non-null  object \n",
      " 5   DISTRITO        32418 non-null  object \n",
      " 6   TIPO ACCIDENTE  32384 non-null  object \n",
      " 7   TIEMPO          29195 non-null  object \n",
      " 8   TIPO VEHICULO   32254 non-null  object \n",
      " 9   TIPO PERSONA    32391 non-null  object \n",
      " 10  RANGO DE EDAD   32420 non-null  object \n",
      " 11  SEXO            28603 non-null  object \n",
      " 12  LESIVIDAD       17614 non-null  float64\n",
      " 13  Unnamed: 13     0 non-null      float64\n",
      " 14  Unnamed: 14     1 non-null      object \n",
      "dtypes: float64(2), object(13)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEXPEDIENTE           0\n",
       "FECHA                 0\n",
       "HORA                  0\n",
       "CALLE                 0\n",
       "NUMERO                2\n",
       "DISTRITO              2\n",
       "TIPO ACCIDENTE       36\n",
       "TIEMPO             3225\n",
       "TIPO VEHICULO       166\n",
       "TIPO PERSONA         29\n",
       "RANGO DE EDAD         0\n",
       "SEXO               3817\n",
       "LESIVIDAD         14806\n",
       "Unnamed: 13       32420\n",
       "Unnamed: 14       32419\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copia = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Obtenemos Info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# df.dtypes[df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1. Si Pandas no reconoce correctamente el tipo de alguna columna, resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no tiene que resolverse en el propio pandas, se pueden utilizar otras herramientas\n",
    "\n",
    "# Tareas\n",
    "# 1. Colocar valor binario 1, y 0 en columna SEXO\n",
    "# 2. Convertiremos blancos en valor 14, y convertimos a texto\n",
    "df['SEXO'] = df['SEXO'].replace(to_replace=[\"Hombre\",\"Mujer\"], value=[0,1])\n",
    "df['LESIVIDAD'] = df['LESIVIDAD'].replace(to_replace=[1, 2,3,4,5,6,7,14,77], value=[\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"14\",\"77\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32420 entries, 0 to 32419\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   NEXPEDIENTE     32420 non-null  object \n",
      " 1   FECHA           32420 non-null  object \n",
      " 2   HORA            32420 non-null  object \n",
      " 3   CALLE           32420 non-null  object \n",
      " 4   NUMERO          32418 non-null  object \n",
      " 5   DISTRITO        32418 non-null  object \n",
      " 6   TIPO ACCIDENTE  32384 non-null  object \n",
      " 7   TIEMPO          29195 non-null  object \n",
      " 8   TIPO VEHICULO   32254 non-null  object \n",
      " 9   TIPO PERSONA    32391 non-null  object \n",
      " 10  RANGO DE EDAD   32420 non-null  object \n",
      " 11  SEXO            28603 non-null  float64\n",
      " 12  LESIVIDAD       17614 non-null  object \n",
      " 13  Unnamed: 13     0 non-null      float64\n",
      " 14  Unnamed: 14     1 non-null      object \n",
      "dtypes: float64(2), object(13)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2. Si tengo columnas fallidas o algo raro que no quiero conservar me lo cargo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32420 entries, 0 to 32419\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   NEXPEDIENTE     32420 non-null  object \n",
      " 1   FECHA           32420 non-null  object \n",
      " 2   HORA            32420 non-null  object \n",
      " 3   CALLE           32420 non-null  object \n",
      " 4   NUMERO          32418 non-null  object \n",
      " 5   DISTRITO        32418 non-null  object \n",
      " 6   TIPO ACCIDENTE  32384 non-null  object \n",
      " 7   TIEMPO          29195 non-null  object \n",
      " 8   TIPO VEHICULO   32254 non-null  object \n",
      " 9   TIPO PERSONA    32391 non-null  object \n",
      " 10  RANGO DE EDAD   32420 non-null  object \n",
      " 11  SEXO            28603 non-null  float64\n",
      " 12  LESIVIDAD       17614 non-null  object \n",
      "dtypes: float64(1), object(12)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 13','Unnamed: 14'],axis=1)\n",
    "# df.drop(['Unnamed: 13','Unnamed: 14'],axis=1, inplace= True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Separamos columnas numéricas de categóricas en listas distintas. Separamos en otra lista las columnas temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericas: ['SEXO']\n",
      "Categoricas: ['NEXPEDIENTE', 'FECHA', 'HORA', 'CALLE', 'NUMERO', 'DISTRITO', 'TIPO ACCIDENTE', 'TIEMPO', 'TIPO VEHICULO', 'TIPO PERSONA', 'RANGO DE EDAD', 'LESIVIDAD']\n",
      "Tiempo: []\n"
     ]
    }
   ],
   "source": [
    "numericas= [x for x in df.dtypes.index if (df.dtypes[x]=='float64' or df.dtypes[x]=='int64')]\n",
    "categoricas= [x for x in df.dtypes.index if df.dtypes[x]=='object']\n",
    "temporales = [x for x in df.dtypes.index if df.dtypes[x]=='datetime64']\n",
    "\n",
    "# otras separaciones podrían ser\n",
    "# if df.dtypes[x]=='bool'\n",
    "# if df.dtypes[x]=='category'\n",
    "print(\"Numericas:\",numericas)\n",
    "print(\"Categoricas:\",categoricas)\n",
    "print(\"Tiempo:\",temporales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Determinamos si tenemos pocos datos. En ese caso, buscaríamos nuevos conjuntos de datos (scrapping, otras fuentes) y los unimos con los que tenemos (por filas o por columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este punto se puede determinar mejor si aplicamos algún tipo de algoritmo a la salida de este DW\n",
    "\n",
    "\n",
    "# Aquellos que quieren saber la verdad sobre el tiempo atmosférico, aquí tendrían que hacer lo de\n",
    "# el AEMET\n",
    "\n",
    "# df['TIEMPOREAL'] = consultarAEMET(df['FECHA'],df['HORA'],df['DISTRITO'])\n",
    "# df.drop(['TIEMPO'],axis=1)\n",
    "\n",
    "# Aquellos que quisieran añadir lo de los puntos negros asociado a calle y numero también aquí\n",
    "\n",
    "# df['PUNTONEGRO'] = deterPuntoNegro(df['CALLE'],df['NUMERO'])  # grado de punto negro\n",
    "# df.drop(['CALLE','NUMERO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Extraemos información necesaria del EDA automático, o del nuestro:\n",
    "##### - Nulos por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "# df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - % valores únicos por filas y columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEXPEDIENTE       14179\n",
      "FECHA               366\n",
      "HORA               1017\n",
      "CALLE              7622\n",
      "NUMERO              489\n",
      "DISTRITO             21\n",
      "TIPO ACCIDENTE       13\n",
      "TIEMPO                7\n",
      "TIPO VEHICULO        35\n",
      "TIPO PERSONA          3\n",
      "RANGO DE EDAD        18\n",
      "SEXO                  2\n",
      "LESIVIDAD             9\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NEXPEDIENTE       14179\n",
       "FECHA               366\n",
       "HORA               1017\n",
       "CALLE              7622\n",
       "NUMERO              489\n",
       "DISTRITO             21\n",
       "TIPO ACCIDENTE       13\n",
       "TIEMPO                7\n",
       "TIPO VEHICULO        35\n",
       "TIPO PERSONA          3\n",
       "RANGO DE EDAD        18\n",
       "LESIVIDAD             9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.nunique())  # columnas\n",
    "# df.nunique(axis=1)  # filas\n",
    "# voy a aplicarlo a las categóricas solo\n",
    "df[categoricas].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de esto podemos decir que PassengerId y Name pueden desaparecer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Número de elementos por categoría en cada una de las columnas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frecuencia de categorias para la columna CALLE\n",
      "PASEO. CASTELLANA                                 1.128933\n",
      "CALL. ALCALA                                      1.048735\n",
      "CALL. BRAVO MURILLO                               0.521283\n",
      "AVDA. ALBUFERA                                    0.444170\n",
      "PASEO. SANTA MARIA DE LA CABEZA                   0.342381\n",
      "                                                    ...   \n",
      "CALL. MANUEL AGUILAR MUÑOZ                        0.003085\n",
      "CALL. ADOLFO BIOY CASARES, C. C. LA GAVIA K/12    0.003085\n",
      "CALL. MEJORANA / CALL. SIERRA DE ALBARRACIN       0.003085\n",
      "AUTOV. M-30, 4,800 CALZADA 1 LATERAL              0.003085\n",
      "CALL. JORGE JUAN / CALL. NARVAEZ                  0.003085\n",
      "Name: CALLE, Length: 7622, dtype: float64\n",
      "\n",
      "Frecuencia de categorias para la columna DISTRITO\n",
      "PUENTE DE VALLECAS     8.134370\n",
      "SALAMANCA              7.622309\n",
      "CIUDAD LINEAL          6.570424\n",
      "CHAMARTÍN              6.400765\n",
      "CARABANCHEL            6.345240\n",
      "FUENCARRAL-EL PARDO    5.509285\n",
      "SAN BLAS-CANILLEJAS    5.484607\n",
      "MONCLOA-ARAVACA        5.404405\n",
      "TETUÁN                 4.917021\n",
      "RETIRO                 4.716516\n",
      "LATINA                 4.688753\n",
      "HORTALEZA              4.688753\n",
      "CENTRO                 4.682584\n",
      "CHAMBERÍ               4.596212\n",
      "ARGANZUELA             4.155099\n",
      "USERA                  3.809612\n",
      "VILLA DE VALLECAS      3.004504\n",
      "MORATALAZ              2.989080\n",
      "VILLAVERDE             2.952064\n",
      "BARAJAS                1.671911\n",
      "VICÁLVARO              1.656487\n",
      "Name: DISTRITO, dtype: float64\n",
      "\n",
      "Frecuencia de categorias para la columna TIPO ACCIDENTE\n",
      "Colisión fronto-lateral         24.644886\n",
      "Alcance                         21.303730\n",
      "Choque contra obstáculo fijo    13.355361\n",
      "Colisión lateral                13.228755\n",
      "Colisión múltiple                6.923172\n",
      "Atropello a persona              6.534091\n",
      "Caída                            6.243824\n",
      "Otro                             3.847579\n",
      "Colisión frontal                 2.782238\n",
      "Solo salida de la vía            0.463192\n",
      "Vuelco                           0.444664\n",
      "Atropello a animal               0.225420\n",
      "Despeñamiento                    0.003088\n",
      "Name: TIPO ACCIDENTE, dtype: float64\n",
      "\n",
      "Frecuencia de categorias para la columna TIEMPO\n",
      "Despejado         83.856825\n",
      "Nublado            6.713478\n",
      "Lluvia débil       6.603871\n",
      "Se desconoce       1.698921\n",
      "LLuvia intensa     1.085802\n",
      "Granizando         0.034252\n",
      "Nevando            0.006850\n",
      "Name: TIEMPO, dtype: float64\n",
      "\n",
      "Frecuencia de categorias para la columna TIPO VEHICULO\n",
      "Turismo                              68.397718\n",
      "Motocicleta hasta 125cc               7.512247\n",
      "Furgoneta                             6.972779\n",
      "Motocicleta > 125cc                   4.284740\n",
      "Camión rígido                         2.526818\n",
      "Bicicleta                             2.461710\n",
      "Autobús                               1.965648\n",
      "Ciclomotor                            1.571898\n",
      "Todo terreno                          1.330068\n",
      "Tractocamión                          0.489862\n",
      "VMU eléctrico                         0.396850\n",
      "Bicicleta EPAC (pedaleo asistido)     0.393750\n",
      "Otros vehículos con motor             0.375147\n",
      "Maquinaria de obras                   0.232529\n",
      "Autobus EMT                           0.213927\n",
      "Autobús articulado                    0.164321\n",
      "Vehículo articulado                   0.151919\n",
      "Patinete                              0.133317\n",
      "Ciclo                                 0.108514\n",
      "Sin especificar                       0.086811\n",
      "Cuadriciclo ligero                    0.062008\n",
      "Cuadriciclo no ligero                 0.040305\n",
      "Moto de tres ruedas > 125cc           0.037205\n",
      "Ambulancia SAMUR                      0.015502\n",
      "Ciclomotor de dos ruedas L1e-B        0.012402\n",
      "Remolque                              0.009301\n",
      "Autocaravana                          0.009301\n",
      "Autobús articulado EMT                0.009301\n",
      "Camión de bomberos                    0.009301\n",
      "Otros vehículos sin motor             0.006201\n",
      "Maquinaria agrícola                   0.006201\n",
      "Tren/metro                            0.003100\n",
      "Moto de tres ruedas hasta 125cc       0.003100\n",
      "Semiremolque                          0.003100\n",
      "Ciclomotor de tres ruedas             0.003100\n",
      "Name: TIPO VEHICULO, dtype: float64\n",
      "\n",
      "Frecuencia de categorias para la columna TIPO PERSONA\n",
      "Conductor    81.794326\n",
      "Pasajero     14.797320\n",
      "Peatón        3.408354\n",
      "Name: TIPO PERSONA, dtype: float64\n",
      "\n",
      "Frecuencia de categorias para la columna RANGO DE EDAD\n",
      "DESCONOCIDA         12.220851\n",
      "DE 25 A 29 AÑOS     10.601481\n",
      "DE 40 A 44 AÑOS     10.484269\n",
      "DE 30 A 34 AÑOS     10.370142\n",
      "DE 35 A 39 AÑOS     10.277606\n",
      "DE 45 A 49 AÑOS      9.512647\n",
      "DE 50 A 54 AÑOS      7.856262\n",
      "DE 21 A 24 AÑOS      6.866132\n",
      "DE 55 A 59 AÑOS      6.406539\n",
      "DE 60 A 64 AÑOS      3.923504\n",
      "DE 18 A 20 AÑOS      3.016656\n",
      "MAYOR DE 74 AÑOS     2.026527\n",
      "DE 65 A 69 AÑOS      1.977175\n",
      "DE 70 A 74 AÑOS      1.317088\n",
      "DE 10 A 14 AÑOS      0.940777\n",
      "DE 0 A 5 AÑOS        0.891425\n",
      "DE 15 A 17 AÑOS      0.771129\n",
      "DE 6 A 9 AÑOS        0.539790\n",
      "Name: RANGO DE EDAD, dtype: float64\n",
      "\n",
      "Frecuencia de categorias para la columna LESIVIDAD\n",
      "14    53.116839\n",
      "07    24.679232\n",
      "02     7.437266\n",
      "01     5.120927\n",
      "06     4.678097\n",
      "05     2.412853\n",
      "03     2.339048\n",
      "04     0.198706\n",
      "77     0.017032\n",
      "Name: LESIVIDAD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for col in categoricas:\n",
    "    if (col !=\"NEXPEDIENTE\" and col!=\"FECHA\" and col!=\"HORA\" and col!=\"NUMERO\"):\n",
    "        print('\\nFrecuencia de categorias para la columna %s'%col)\n",
    "        print(df[col].value_counts(normalize=True)*100)\n",
    "\n",
    "# Intentamos localizar si hay categorias raras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Posibles Outliers en columnas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución normal gausiana\n",
    "for col in numericas:\n",
    "    Ug = df[col].mean() + 3* df[col].std()\n",
    "    Lg = df[col].mean() - 3* df[col].std()\n",
    "    print(\"Calculo limite outliers (Gausiana) para la columna \",col)\n",
    "    print(\"Superior:\",Ug,\"Inferior:\",Lg)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Número de posibles outliers en la columna\",col)\n",
    "    print('Menos que L3.0 Normal: {}'.format(df[df[col] < Lg].shape[0]))\n",
    "    print('Mas que U3.0 Normal: {}'.format(df[df[col] > Ug].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculo limite outliers (IQR 1.5) para la columna  SEXO\n",
      "Superior: 2.5 Inferior: -1.5 IQR: 1.0\n",
      "--------------------------------------------------\n",
      "Número de posibles outliers en la columna SEXO\n",
      "Menos que L1.5: 0\n",
      "Mas que U1.5: 0\n"
     ]
    }
   ],
   "source": [
    "# Distribución IQR 1.5 (no normal)\n",
    "for col in numericas:\n",
    "    IQR15 = df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "    L15 = df[col].quantile(0.25) - (IQR15 * 1.5)\n",
    "    U15 = df[col].quantile(0.75) + (IQR15 * 1.5)\n",
    "    print(\"Calculo limite outliers (IQR 1.5) para la columna \",col)\n",
    "    print(\"Superior:\",U15,\"Inferior:\",L15,\"IQR:\",IQR15)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Número de posibles outliers en la columna\",col)\n",
    "    print('Menos que L1.5: {}'.format(df[df[col] < L15].shape[0]))\n",
    "    print('Mas que U1.5: {}'.format(df[df[col] > U15].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución IQR 3 (extrema no normal)\n",
    "for col in numericas:\n",
    "    IQR3 = df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "    L3 = df[col].quantile(0.25) - (IQR3 * 3)\n",
    "    U3 = df[col].quantile(0.75) + (IQR3 * 3)\n",
    "    print(\"Calculo limite outliers (IQR 3) para la columna \",col)\n",
    "    print(\"Superior:\",U3,\"Inferior:\",L3,\"IQR:\",IQR3)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Número de posibles outliers en la columna\",col)\n",
    "    print('Menos que L3.0: {}'.format(df[df[col] < L3].shape[0]))\n",
    "    print('Mas que U3.0: {}'.format(df[df[col] > U3].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Filas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1514"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n",
    "\n",
    "# Las conservamos porque con la granularidad que podemos asegurar nada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Columnas con datos no adecuados (Opciona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. En cada fila cuya valor en columna TIPOPERSONA = \"Peatón\" cambiar columna TIPOVEHICULO= \"ninguno\"\n",
    "#     Forma df.iterrows() (Tarda MUUUUUUCHOOOOOO)\n",
    "\n",
    "#     Forma lambda\n",
    "# df['TIPO VEHICULO']= df.apply(lambda x: \"NINGUNO\" if x['TIPO PERSONA']==\"Peatón\" else x['TIPO VEHICULO'] ,axis=1)\n",
    "\n",
    "# 2. Cambiar en RANGO DE EDAD cambiar DESCONOCIDA por np.nan \n",
    "df['RANGO DE EDAD'] = df['RANGO DE EDAD'].apply(lambda x: np.nan if x==\"DESCONOCIDA\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEXPEDIENTE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>CALLE</th>\n",
       "      <th>NUMERO</th>\n",
       "      <th>DISTRITO</th>\n",
       "      <th>TIPO ACCIDENTE</th>\n",
       "      <th>TIEMPO</th>\n",
       "      <th>TIPO VEHICULO</th>\n",
       "      <th>TIPO PERSONA</th>\n",
       "      <th>RANGO DE EDAD</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>LESIVIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020S000057</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>23:15</td>\n",
       "      <td>AVDA. CIUDAD DE BARCELONA / CALL. DOCTOR ESQUERDO</td>\n",
       "      <td>-</td>\n",
       "      <td>RETIRO</td>\n",
       "      <td>Choque contra obstáculo fijo</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 25 A 29 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020S000038</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>22:35</td>\n",
       "      <td>CALL. VALLE DE TORANZO / CALL. SIERRA DE PAJAREJO</td>\n",
       "      <td>-</td>\n",
       "      <td>MONCLOA-ARAVACA</td>\n",
       "      <td>Caída</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Ciclomotor</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 21 A 24 AÑOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020S000060</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>20:15</td>\n",
       "      <td>GTA. MARIANO SALVADOR MAELLA</td>\n",
       "      <td>1</td>\n",
       "      <td>FUENCARRAL-EL PARDO</td>\n",
       "      <td>Caída</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 45 A 49 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020S000060</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>20:15</td>\n",
       "      <td>GTA. MARIANO SALVADOR MAELLA</td>\n",
       "      <td>1</td>\n",
       "      <td>FUENCARRAL-EL PARDO</td>\n",
       "      <td>Caída</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Motocicleta hasta 125cc</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 25 A 29 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020S000033</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>19:45</td>\n",
       "      <td>CALL. OLIVAR</td>\n",
       "      <td>40</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>Choque contra obstáculo fijo</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32415</th>\n",
       "      <td>2020S019527</td>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>0:18</td>\n",
       "      <td>AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS</td>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32416</th>\n",
       "      <td>2020S019527</td>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>0:18</td>\n",
       "      <td>AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS</td>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32417</th>\n",
       "      <td>2020S019527</td>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>0:18</td>\n",
       "      <td>AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS</td>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32418</th>\n",
       "      <td>2020S019527</td>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>0:18</td>\n",
       "      <td>AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS</td>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32419</th>\n",
       "      <td>2020S019527</td>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>0:18</td>\n",
       "      <td>AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS</td>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32420 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NEXPEDIENTE       FECHA   HORA  \\\n",
       "0      2020S000057  01/01/2020  23:15   \n",
       "1      2020S000038  01/01/2020  22:35   \n",
       "2      2020S000060  01/01/2020  20:15   \n",
       "3      2020S000060  01/01/2020  20:15   \n",
       "4      2020S000033  01/01/2020  19:45   \n",
       "...            ...         ...    ...   \n",
       "32415  2020S019527  31/12/2020   0:18   \n",
       "32416  2020S019527  31/12/2020   0:18   \n",
       "32417  2020S019527  31/12/2020   0:18   \n",
       "32418  2020S019527  31/12/2020   0:18   \n",
       "32419  2020S019527  31/12/2020   0:18   \n",
       "\n",
       "                                                   CALLE NUMERO  \\\n",
       "0      AVDA. CIUDAD DE BARCELONA / CALL. DOCTOR ESQUERDO      -   \n",
       "1      CALL. VALLE DE TORANZO / CALL. SIERRA DE PAJAREJO      -   \n",
       "2                           GTA. MARIANO SALVADOR MAELLA      1   \n",
       "3                           GTA. MARIANO SALVADOR MAELLA      1   \n",
       "4                                           CALL. OLIVAR     40   \n",
       "...                                                  ...    ...   \n",
       "32415          AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS      -   \n",
       "32416          AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS      -   \n",
       "32417          AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS      -   \n",
       "32418          AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS      -   \n",
       "32419          AVDA. ALFONSO XIII / CALL. LOPEZ DE HOYOS      -   \n",
       "\n",
       "                  DISTRITO                TIPO ACCIDENTE     TIEMPO  \\\n",
       "0                   RETIRO  Choque contra obstáculo fijo  Despejado   \n",
       "1          MONCLOA-ARAVACA                         Caída  Despejado   \n",
       "2      FUENCARRAL-EL PARDO                         Caída  Despejado   \n",
       "3      FUENCARRAL-EL PARDO                         Caída  Despejado   \n",
       "4                   CENTRO  Choque contra obstáculo fijo  Despejado   \n",
       "...                    ...                           ...        ...   \n",
       "32415            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "32416            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "32417            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "32418            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "32419            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "\n",
       "                 TIPO VEHICULO TIPO PERSONA    RANGO DE EDAD  SEXO LESIVIDAD  \n",
       "0                      Turismo    Conductor  DE 25 A 29 AÑOS   0.0        14  \n",
       "1                   Ciclomotor    Conductor  DE 21 A 24 AÑOS   1.0        06  \n",
       "2                      Turismo    Conductor  DE 45 A 49 AÑOS   0.0        14  \n",
       "3      Motocicleta hasta 125cc    Conductor  DE 25 A 29 AÑOS   0.0        07  \n",
       "4                      Turismo    Conductor              NaN   NaN        14  \n",
       "...                        ...          ...              ...   ...       ...  \n",
       "32415                  Turismo     Pasajero  DE 35 A 39 AÑOS   0.0        14  \n",
       "32416                  Turismo     Pasajero  DE 35 A 39 AÑOS   0.0        14  \n",
       "32417                  Turismo    Conductor  DE 35 A 39 AÑOS   0.0        14  \n",
       "32418                  Turismo     Pasajero  DE 35 A 39 AÑOS   0.0        14  \n",
       "32419                  Turismo     Pasajero  DE 35 A 39 AÑOS   0.0        14  \n",
       "\n",
       "[32420 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - (Opcional) Eliminar todos los elementos no deseados, convertir a númerico (OneHot, LabelEncoding) y realizar un Feature Importances preeliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### añadir datos a las filas Columnas con datos no adecuados CON LAMBDA###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIPO VEHICULO'] = df.apply(lambda x: \"NINGUNO\" if x['TIPO PERSONA'] == \"Peaton\" else x['TIPO VEHICULO'] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cambiar en RANGO DE EDAD caambiar DESCONOCIDA por np.nan</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RANGO EDAD'] = df['RANGO DE EDAD'].apply(lambda x: np.nan if x==\"DESCONOCIDA\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Limpieza de nulos\n",
    "##### - Estrategia: Eliminación \"con violencia\" de filas o columnas con nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con opcion o no de crear una columna que indique si cada fila tenía o no nulos\n",
    "# realizar el volcado antes de eliminar la columna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino todas las columnas que tengan algun nulo\n",
    "df.dropna(axis=1)\n",
    "# elimino todas las filas que tengan algun nulo\n",
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todas las columnas con todos nulos\n",
    "df.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todas las filas con todos nulos\n",
    "df.dropna(axis=0,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de que quiera eliminar filas de una columna cualquiera.\n",
    "df['nombre de la columna'].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUMERO', 'DISTRITO', 'TIPO ACCIDENTE', 'TIEMPO', 'TIPO VEHICULO', 'TIPO PERSONA', 'SEXO', 'LESIVIDAD']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4e260d7ad763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mclnul\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclnul\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcolumna\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nombre de columna a eliminar:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolumna\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclnul\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mcorrecto\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m         )\n\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# eliminar una determinada columna (porque sí)\n",
    "correcto = False\n",
    "while not(correcto):\n",
    "    clnul = []\n",
    "    for cl in df.columns:\n",
    "        if df[cl].isnull().sum()>0:\n",
    "            clnul.append(cl)\n",
    "    print(clnul)\n",
    "    columna = input(\"Nombre de columna a eliminar:\")\n",
    "    if columna in clnul:\n",
    "        correcto=True\n",
    "        del df[columna]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Estrategia: rellenado valor fijo (con 0s, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUMERO', 'DISTRITO', 'TIPO ACCIDENTE', 'TIEMPO', 'TIPO VEHICULO', 'TIPO PERSONA', 'SEXO', 'LESIVIDAD']\n",
      "Nombre de columna a rellenarLESIVIDAD\n"
     ]
    }
   ],
   "source": [
    "# rellenar una determinada columna con valor fijo\n",
    "# aquí determinamos el valor fijo con el que rellenar\n",
    "valor_fijo = \"14\"\n",
    "# comenzamos\n",
    "correcto = False\n",
    "while not(correcto):\n",
    "    clnul = []\n",
    "    for cl in df.columns:\n",
    "        if df[cl].isnull().sum()>0:\n",
    "            clnul.append(cl)\n",
    "    print(clnul)\n",
    "    columna = input(\"Nombre de columna a rellenar\")\n",
    "    if columna in clnul:\n",
    "        correcto=True\n",
    "        df[columna].fillna(valor_fijo, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEXPEDIENTE          0\n",
       "FECHA                0\n",
       "HORA                 0\n",
       "CALLE                0\n",
       "NUMERO               2\n",
       "DISTRITO             2\n",
       "TIPO ACCIDENTE      36\n",
       "TIEMPO            3225\n",
       "TIPO VEHICULO      166\n",
       "TIPO PERSONA        29\n",
       "RANGO DE EDAD     3962\n",
       "SEXO              3817\n",
       "LESIVIDAD            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Estrategia: media, mediana, moda (En categóricos, se utiliza el \"valor más frecuente\" algo parecido a la moda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellenar una determinada columna con media, mediana o moda en numéricas\n",
    "correcto = False\n",
    "while not(correcto):\n",
    "    clnul = []\n",
    "    for cl in numericas:\n",
    "        if df[cl].isnull().sum()>0:\n",
    "            clnul.append(cl)\n",
    "    print(clnul)\n",
    "    columna = input(\"Nombre de columna a rellenar:\")\n",
    "    if columna in clnul:\n",
    "        correcto=True\n",
    "        operacion = \"\"\n",
    "        while operacion not in [\"mediana\",\"moda\",\"media\"]:\n",
    "            operacion = input(\"Operacion de relleno (mediana/media/moda):\")\n",
    "            if operacion == \"mediana\":\n",
    "                m = df[columna].median()\n",
    "            elif operacion == \"media\":\n",
    "                m = df[columna].mean()\n",
    "            elif operacion == \"moda\":\n",
    "                m = df[columna].mode()\n",
    "            else:\n",
    "                print(\"Escoger una de las tres posibles\")\n",
    "                \n",
    "        df[columna].fillna(m,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellenar una determinada columna con el valor más frecuente en categóricas\n",
    "correcto = False\n",
    "while not(correcto):\n",
    "    clnul = []\n",
    "    for cl in categoricas:\n",
    "        if df[cl].isnull().sum()>0:\n",
    "            clnul.append(cl)\n",
    "    print(clnul)\n",
    "    columna = input(\"Nombre de columna a rellenar:\")\n",
    "    if columna in clnul:\n",
    "        correcto=True\n",
    "        mas_frecuente = df.groupby([columna])[columna].count().sort_values(ascending=False).index[0]\n",
    "        print(\"Se rellenará con\",mas_frecuente)\n",
    "        df[columna].fillna(mas_frecuente,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Estrategia: valores extremos de la distribución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo para numéricas\n",
    "correcto = False\n",
    "while not(correcto):\n",
    "    clnul = []\n",
    "    for cl in numericas:\n",
    "        if df[cl].isnull().sum()>0:\n",
    "            clnul.append(cl)\n",
    "    print(clnul)\n",
    "    columna = input(\"Nombre de columna a rellenar:\")\n",
    "    if columna in clnul:\n",
    "        correcto=True\n",
    "        factor_extremo = int(input(\"Introduzca el factor (1.5/2/2.5/3):\"))\n",
    "        mediana = df[columna].median()\n",
    "        extremo = df[columna].mean()+factor_extremo*df[columna].std()\n",
    "        # extremo = df[columna].mean()-factor_extremo*df[columna].std()\n",
    "        df[columna].fillna(extremo, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Estrategia: valores aleatorios dentro del rango de valores de la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUMERO', 'DISTRITO', 'TIPO ACCIDENTE', 'TIEMPO', 'TIPO VEHICULO', 'TIPO PERSONA', 'RANGO DE EDAD', 'SEXO']\n",
      "Nombre de columna a rellenar:NUMERO\n"
     ]
    }
   ],
   "source": [
    "# sirve para todas las columnas\n",
    "# definimos la función que lo va a hacer todo\n",
    "def random_na(df, variable):\n",
    "    # creamos la variable\n",
    "    df[variable+'_random'] = df[variable]\n",
    "    # Tomamos la muestra aleatoria para rellenar\n",
    "    \n",
    "    random_sample = df[variable].sample(df[variable].isnull().sum(), random_state=0)\n",
    "    # pandas necesita que los dos datasets tengan el mismo indice para que los pueda encajar\n",
    "    random_sample.index = df[df[variable].isnull()].index\n",
    "    df.loc[df[variable].isnull(), variable+'_random'] = random_sample\n",
    "    return df\n",
    "    \n",
    "correcto = False\n",
    "while not(correcto):\n",
    "    clnul = []\n",
    "    for cl in df.columns:\n",
    "        if df[cl].isnull().sum()>0:\n",
    "            clnul.append(cl)\n",
    "    print(clnul)\n",
    "    columna = input(\"Nombre de columna a rellenar:\")\n",
    "    if columna in clnul:\n",
    "        correcto=True\n",
    "        # llamamos a la funcion anterior\n",
    "        df = random_na(df,columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEXPEDIENTE          0\n",
       "FECHA                0\n",
       "HORA                 0\n",
       "CALLE                0\n",
       "NUMERO               2\n",
       "DISTRITO             2\n",
       "TIPO ACCIDENTE      36\n",
       "TIEMPO            3225\n",
       "TIPO VEHICULO      166\n",
       "TIPO PERSONA        29\n",
       "RANGO DE EDAD     3962\n",
       "SEXO              3817\n",
       "LESIVIDAD            0\n",
       "NUMERO_random        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Estrategia: ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columna</th>\n",
       "      <th>cardinalidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEXPEDIENTE</td>\n",
       "      <td>0.437353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>0.235102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HORA</td>\n",
       "      <td>0.031370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NUMERO</td>\n",
       "      <td>0.015083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUMERO_random</td>\n",
       "      <td>0.015083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FECHA</td>\n",
       "      <td>0.011289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TIPO VEHICULO</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DISTRITO</td>\n",
       "      <td>0.000648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RANGO DE EDAD</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TIPO ACCIDENTE</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LESIVIDAD</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TIEMPO</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TIPO PERSONA</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SEXO</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           columna  cardinalidad\n",
       "0      NEXPEDIENTE      0.437353\n",
       "1            CALLE      0.235102\n",
       "2             HORA      0.031370\n",
       "3           NUMERO      0.015083\n",
       "4    NUMERO_random      0.015083\n",
       "5            FECHA      0.011289\n",
       "6    TIPO VEHICULO      0.001080\n",
       "7         DISTRITO      0.000648\n",
       "8    RANGO DE EDAD      0.000524\n",
       "9   TIPO ACCIDENTE      0.000401\n",
       "10       LESIVIDAD      0.000278\n",
       "11          TIEMPO      0.000216\n",
       "12    TIPO PERSONA      0.000093\n",
       "13            SEXO      0.000062"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resolver el tema de one_hot y que ya te aparte las de alta cardinalidad\n",
    "df_u = df.nunique()/df.shape[0]\n",
    "df_u = df_u.sort_values(ascending=False).rename('cardinalidad')\n",
    "df_uf = df_u.rename_axis('columna').reset_index()\n",
    "df_uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduce el % limite máximo de cardinalidad: Entre 0 y 100:50\n",
      "Lista negra []\n"
     ]
    }
   ],
   "source": [
    "lista_negra = []\n",
    "limite = int(input(\"Introduce el % limite máximo de cardinalidad: Entre 0 y 100:\"))\n",
    "limite = limite /100\n",
    "for index, row in df_uf.iterrows():\n",
    "    if row['cardinalidad']>=limite:\n",
    "        if row['columna'] in categoricas:\n",
    "            lista_negra.append(row['columna'])\n",
    "print(\"Lista negra\",lista_negra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEXPEDIENTE          0\n",
       "FECHA                0\n",
       "HORA                 0\n",
       "CALLE                0\n",
       "LESIVIDAD            0\n",
       "NUMERO_random        0\n",
       "NUMERO               2\n",
       "DISTRITO             2\n",
       "TIPO PERSONA        29\n",
       "TIPO ACCIDENTE      36\n",
       "TIPO VEHICULO      166\n",
       "TIEMPO            3225\n",
       "SEXO              3817\n",
       "RANGO DE EDAD     3962\n",
       "Name: suma, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null = df.isnull().sum().sort_values(ascending=True).rename('suma')\n",
    "df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columna</th>\n",
       "      <th>suma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEXPEDIENTE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FECHA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HORA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LESIVIDAD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NUMERO_random</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NUMERO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DISTRITO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TIPO PERSONA</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TIPO ACCIDENTE</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TIPO VEHICULO</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TIEMPO</td>\n",
       "      <td>3225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SEXO</td>\n",
       "      <td>3817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RANGO DE EDAD</td>\n",
       "      <td>3962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           columna  suma\n",
       "0      NEXPEDIENTE     0\n",
       "1            FECHA     0\n",
       "2             HORA     0\n",
       "3            CALLE     0\n",
       "4        LESIVIDAD     0\n",
       "5    NUMERO_random     0\n",
       "6           NUMERO     2\n",
       "7         DISTRITO     2\n",
       "8     TIPO PERSONA    29\n",
       "9   TIPO ACCIDENTE    36\n",
       "10   TIPO VEHICULO   166\n",
       "11          TIEMPO  3225\n",
       "12            SEXO  3817\n",
       "13   RANGO DE EDAD  3962"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Ordenar las columnas por número de nulos que tengan\n",
    "df_null = df.isnull().sum().sort_values(ascending=True).rename('suma')\n",
    "# Convirtiendo el índice que son las columnas en Columna\n",
    "dford = df_null.rename_axis('columna').reset_index()\n",
    "dford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin nulos ['NEXPEDIENTE', 'FECHA', 'HORA', 'CALLE', 'LESIVIDAD', 'NUMERO_random']\n",
      "Con nulos ['NUMERO', 'DISTRITO', 'TIPO PERSONA', 'TIPO ACCIDENTE', 'TIPO VEHICULO', 'TIEMPO', 'SEXO', 'RANGO DE EDAD']\n"
     ]
    }
   ],
   "source": [
    "# y ahora recorremos las filas para que las columnas con valor 0 pasarán a la lista_sin\n",
    "# el resto pasarán a lista_con\n",
    "lista_sin = []\n",
    "lista_con = []\n",
    "for index, row in dford.iterrows():\n",
    "    if row['suma']==0:\n",
    "        lista_sin.append(row['columna'])\n",
    "    else:\n",
    "        lista_con.append(row['columna'])\n",
    "print(\"Sin nulos\",lista_sin)\n",
    "print(\"Con nulos\",lista_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista negra []\n",
      "\n",
      "Antigua lista sin nulos ['NEXPEDIENTE', 'FECHA', 'HORA', 'CALLE', 'LESIVIDAD', 'NUMERO_random']\n",
      "Nueva lista sin nulos ['NEXPEDIENTE', 'FECHA', 'HORA', 'CALLE', 'LESIVIDAD', 'NUMERO_random']\n",
      "Antigua lista con nulos ['NUMERO', 'DISTRITO', 'TIPO PERSONA', 'TIPO ACCIDENTE', 'TIPO VEHICULO', 'TIEMPO', 'SEXO', 'RANGO DE EDAD']\n",
      "Nueva lista con nulos ['NUMERO', 'DISTRITO', 'TIPO PERSONA', 'TIPO ACCIDENTE', 'TIPO VEHICULO', 'TIEMPO', 'SEXO', 'RANGO DE EDAD']\n",
      "\n",
      "Lista para aplicar one_hot ['NEXPEDIENTE', 'FECHA', 'HORA', 'CALLE', 'LESIVIDAD']\n"
     ]
    }
   ],
   "source": [
    "# antes de pasar a aplicar fillML, vamos a quitar aquellas columnas con alta cardinalidad\n",
    "# que hemos puesto en la lista negra y asignaremos a quién habrá que hacerle el one-hot\n",
    "n_lista_sin=[]\n",
    "n_lista_one =[]\n",
    "for col in lista_sin:\n",
    "    if col not in lista_negra:\n",
    "        n_lista_sin.append(col)\n",
    "        if col in categoricas:\n",
    "            n_lista_one.append(col)\n",
    "\n",
    "n_lista_con=[]\n",
    "for col in lista_con:\n",
    "    if col not in lista_negra:\n",
    "        n_lista_con.append(col)\n",
    "\n",
    "print(\"Lista negra\",lista_negra)\n",
    "print(\"\\nAntigua lista sin nulos\",lista_sin)        \n",
    "print(\"Nueva lista sin nulos\",n_lista_sin)\n",
    "print(\"Antigua lista con nulos\",lista_con)\n",
    "print(\"Nueva lista con nulos\",n_lista_con)\n",
    "print(\"\\nLista para aplicar one_hot\",n_lista_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NEXPEDIENTE_2019S040011', 'NEXPEDIENTE_2020S000001',\n",
      "       'NEXPEDIENTE_2020S000002', 'NEXPEDIENTE_2020S000003',\n",
      "       'NEXPEDIENTE_2020S000004', 'NEXPEDIENTE_2020S000005',\n",
      "       'NEXPEDIENTE_2020S000006', 'NEXPEDIENTE_2020S000007',\n",
      "       'NEXPEDIENTE_2020S000009', 'NEXPEDIENTE_2020S000012',\n",
      "       ...\n",
      "       'CALLE_sandalo 3', 'LESIVIDAD_01', 'LESIVIDAD_02', 'LESIVIDAD_03',\n",
      "       'LESIVIDAD_04', 'LESIVIDAD_05', 'LESIVIDAD_06', 'LESIVIDAD_07',\n",
      "       'LESIVIDAD_14', 'LESIVIDAD_77'],\n",
      "      dtype='object', length=23193)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEXPEDIENTE_2019S040011</th>\n",
       "      <th>NEXPEDIENTE_2020S000001</th>\n",
       "      <th>NEXPEDIENTE_2020S000002</th>\n",
       "      <th>NEXPEDIENTE_2020S000003</th>\n",
       "      <th>NEXPEDIENTE_2020S000004</th>\n",
       "      <th>NEXPEDIENTE_2020S000005</th>\n",
       "      <th>NEXPEDIENTE_2020S000006</th>\n",
       "      <th>NEXPEDIENTE_2020S000007</th>\n",
       "      <th>NEXPEDIENTE_2020S000009</th>\n",
       "      <th>NEXPEDIENTE_2020S000012</th>\n",
       "      <th>...</th>\n",
       "      <th>CALLE_sandalo 3</th>\n",
       "      <th>LESIVIDAD_01</th>\n",
       "      <th>LESIVIDAD_02</th>\n",
       "      <th>LESIVIDAD_03</th>\n",
       "      <th>LESIVIDAD_04</th>\n",
       "      <th>LESIVIDAD_05</th>\n",
       "      <th>LESIVIDAD_06</th>\n",
       "      <th>LESIVIDAD_07</th>\n",
       "      <th>LESIVIDAD_14</th>\n",
       "      <th>LESIVIDAD_77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32418</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32419</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32420 rows × 23193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NEXPEDIENTE_2019S040011  NEXPEDIENTE_2020S000001  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "...                        ...                      ...   \n",
       "32415                        0                        0   \n",
       "32416                        0                        0   \n",
       "32417                        0                        0   \n",
       "32418                        0                        0   \n",
       "32419                        0                        0   \n",
       "\n",
       "       NEXPEDIENTE_2020S000002  NEXPEDIENTE_2020S000003  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "...                        ...                      ...   \n",
       "32415                        0                        0   \n",
       "32416                        0                        0   \n",
       "32417                        0                        0   \n",
       "32418                        0                        0   \n",
       "32419                        0                        0   \n",
       "\n",
       "       NEXPEDIENTE_2020S000004  NEXPEDIENTE_2020S000005  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "...                        ...                      ...   \n",
       "32415                        0                        0   \n",
       "32416                        0                        0   \n",
       "32417                        0                        0   \n",
       "32418                        0                        0   \n",
       "32419                        0                        0   \n",
       "\n",
       "       NEXPEDIENTE_2020S000006  NEXPEDIENTE_2020S000007  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "...                        ...                      ...   \n",
       "32415                        0                        0   \n",
       "32416                        0                        0   \n",
       "32417                        0                        0   \n",
       "32418                        0                        0   \n",
       "32419                        0                        0   \n",
       "\n",
       "       NEXPEDIENTE_2020S000009  NEXPEDIENTE_2020S000012  ...  CALLE_sandalo 3  \\\n",
       "0                            0                        0  ...                0   \n",
       "1                            0                        0  ...                0   \n",
       "2                            0                        0  ...                0   \n",
       "3                            0                        0  ...                0   \n",
       "4                            0                        0  ...                0   \n",
       "...                        ...                      ...  ...              ...   \n",
       "32415                        0                        0  ...                0   \n",
       "32416                        0                        0  ...                0   \n",
       "32417                        0                        0  ...                0   \n",
       "32418                        0                        0  ...                0   \n",
       "32419                        0                        0  ...                0   \n",
       "\n",
       "       LESIVIDAD_01  LESIVIDAD_02  LESIVIDAD_03  LESIVIDAD_04  LESIVIDAD_05  \\\n",
       "0                 0             0             0             0             0   \n",
       "1                 0             0             0             0             0   \n",
       "2                 0             0             0             0             0   \n",
       "3                 0             0             0             0             0   \n",
       "4                 0             0             0             0             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "32415             0             0             0             0             0   \n",
       "32416             0             0             0             0             0   \n",
       "32417             0             0             0             0             0   \n",
       "32418             0             0             0             0             0   \n",
       "32419             0             0             0             0             0   \n",
       "\n",
       "       LESIVIDAD_06  LESIVIDAD_07  LESIVIDAD_14  LESIVIDAD_77  \n",
       "0                 0             0             1             0  \n",
       "1                 1             0             0             0  \n",
       "2                 0             0             1             0  \n",
       "3                 0             1             0             0  \n",
       "4                 0             0             1             0  \n",
       "...             ...           ...           ...           ...  \n",
       "32415             0             0             1             0  \n",
       "32416             0             0             1             0  \n",
       "32417             0             0             1             0  \n",
       "32418             0             0             1             0  \n",
       "32419             0             0             1             0  \n",
       "\n",
       "[32420 rows x 23193 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y ahora, hacemos un one hot ultra rápido para todas aquellas categóricas que nos queden en\n",
    "# lista_sin\n",
    "\n",
    "# Se podria hacer de este modo hasta la versión 1.19 de pandas\n",
    "df_ML=df.copy()\n",
    "df_one = pd.get_dummies(data=df_ML[n_lista_one], columns=n_lista_one)\n",
    "columnas = df_one.columns\n",
    "print(columnas)\n",
    "df_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMERO</th>\n",
       "      <th>DISTRITO</th>\n",
       "      <th>TIPO ACCIDENTE</th>\n",
       "      <th>TIEMPO</th>\n",
       "      <th>TIPO VEHICULO</th>\n",
       "      <th>TIPO PERSONA</th>\n",
       "      <th>RANGO DE EDAD</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>NUMERO_random</th>\n",
       "      <th>NEXPEDIENTE_2019S040011</th>\n",
       "      <th>...</th>\n",
       "      <th>CALLE_sandalo 3</th>\n",
       "      <th>LESIVIDAD_01</th>\n",
       "      <th>LESIVIDAD_02</th>\n",
       "      <th>LESIVIDAD_03</th>\n",
       "      <th>LESIVIDAD_04</th>\n",
       "      <th>LESIVIDAD_05</th>\n",
       "      <th>LESIVIDAD_06</th>\n",
       "      <th>LESIVIDAD_07</th>\n",
       "      <th>LESIVIDAD_14</th>\n",
       "      <th>LESIVIDAD_77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>RETIRO</td>\n",
       "      <td>Choque contra obstáculo fijo</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 25 A 29 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>MONCLOA-ARAVACA</td>\n",
       "      <td>Caída</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Ciclomotor</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 21 A 24 AÑOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>FUENCARRAL-EL PARDO</td>\n",
       "      <td>Caída</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 45 A 49 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>FUENCARRAL-EL PARDO</td>\n",
       "      <td>Caída</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Motocicleta hasta 125cc</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 25 A 29 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>Choque contra obstáculo fijo</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32415</th>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32416</th>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32417</th>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32418</th>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32419</th>\n",
       "      <td>-</td>\n",
       "      <td>CHAMARTÍN</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>DE 35 A 39 AÑOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32420 rows × 23202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NUMERO             DISTRITO                TIPO ACCIDENTE     TIEMPO  \\\n",
       "0          -               RETIRO  Choque contra obstáculo fijo  Despejado   \n",
       "1          -      MONCLOA-ARAVACA                         Caída  Despejado   \n",
       "2          1  FUENCARRAL-EL PARDO                         Caída  Despejado   \n",
       "3          1  FUENCARRAL-EL PARDO                         Caída  Despejado   \n",
       "4         40               CENTRO  Choque contra obstáculo fijo  Despejado   \n",
       "...      ...                  ...                           ...        ...   \n",
       "32415      -            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "32416      -            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "32417      -            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "32418      -            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "32419      -            CHAMARTÍN              Colisión lateral  Despejado   \n",
       "\n",
       "                 TIPO VEHICULO TIPO PERSONA    RANGO DE EDAD  SEXO  \\\n",
       "0                      Turismo    Conductor  DE 25 A 29 AÑOS   0.0   \n",
       "1                   Ciclomotor    Conductor  DE 21 A 24 AÑOS   1.0   \n",
       "2                      Turismo    Conductor  DE 45 A 49 AÑOS   0.0   \n",
       "3      Motocicleta hasta 125cc    Conductor  DE 25 A 29 AÑOS   0.0   \n",
       "4                      Turismo    Conductor              NaN   NaN   \n",
       "...                        ...          ...              ...   ...   \n",
       "32415                  Turismo     Pasajero  DE 35 A 39 AÑOS   0.0   \n",
       "32416                  Turismo     Pasajero  DE 35 A 39 AÑOS   0.0   \n",
       "32417                  Turismo    Conductor  DE 35 A 39 AÑOS   0.0   \n",
       "32418                  Turismo     Pasajero  DE 35 A 39 AÑOS   0.0   \n",
       "32419                  Turismo     Pasajero  DE 35 A 39 AÑOS   0.0   \n",
       "\n",
       "      NUMERO_random  NEXPEDIENTE_2019S040011  ...  CALLE_sandalo 3  \\\n",
       "0                 -                        0  ...                0   \n",
       "1                 -                        0  ...                0   \n",
       "2                 1                        0  ...                0   \n",
       "3                 1                        0  ...                0   \n",
       "4                40                        0  ...                0   \n",
       "...             ...                      ...  ...              ...   \n",
       "32415             -                        0  ...                0   \n",
       "32416             -                        0  ...                0   \n",
       "32417             -                        0  ...                0   \n",
       "32418             -                        0  ...                0   \n",
       "32419             -                        0  ...                0   \n",
       "\n",
       "       LESIVIDAD_01  LESIVIDAD_02  LESIVIDAD_03  LESIVIDAD_04  LESIVIDAD_05  \\\n",
       "0                 0             0             0             0             0   \n",
       "1                 0             0             0             0             0   \n",
       "2                 0             0             0             0             0   \n",
       "3                 0             0             0             0             0   \n",
       "4                 0             0             0             0             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "32415             0             0             0             0             0   \n",
       "32416             0             0             0             0             0   \n",
       "32417             0             0             0             0             0   \n",
       "32418             0             0             0             0             0   \n",
       "32419             0             0             0             0             0   \n",
       "\n",
       "       LESIVIDAD_06  LESIVIDAD_07  LESIVIDAD_14  LESIVIDAD_77  \n",
       "0                 0             0             1             0  \n",
       "1                 1             0             0             0  \n",
       "2                 0             0             1             0  \n",
       "3                 0             1             0             0  \n",
       "4                 0             0             1             0  \n",
       "...             ...           ...           ...           ...  \n",
       "32415             0             0             1             0  \n",
       "32416             0             0             1             0  \n",
       "32417             0             0             1             0  \n",
       "32418             0             0             1             0  \n",
       "32419             0             0             1             0  \n",
       "\n",
       "[32420 rows x 23202 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y ahora primero las pasamos al df\n",
    "df_ML=df_ML.drop(n_lista_one,axis=1)\n",
    "df_ML =pd.concat([df_ML,df_one],axis=1)\n",
    "df_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_lista_sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quitamos de n_lista_sin las columnas de n_lista_one\n",
    "for ele in n_lista_one:\n",
    "    n_lista_sin.remove(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUMERO_random']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NUMERO_random',\n",
       " 'NEXPEDIENTE_2019S040011',\n",
       " 'NEXPEDIENTE_2020S000001',\n",
       " 'NEXPEDIENTE_2020S000002',\n",
       " 'NEXPEDIENTE_2020S000003',\n",
       " 'NEXPEDIENTE_2020S000004',\n",
       " 'NEXPEDIENTE_2020S000005',\n",
       " 'NEXPEDIENTE_2020S000006',\n",
       " 'NEXPEDIENTE_2020S000007',\n",
       " 'NEXPEDIENTE_2020S000009',\n",
       " 'NEXPEDIENTE_2020S000012',\n",
       " 'NEXPEDIENTE_2020S000013',\n",
       " 'NEXPEDIENTE_2020S000014',\n",
       " 'NEXPEDIENTE_2020S000015',\n",
       " 'NEXPEDIENTE_2020S000017',\n",
       " 'NEXPEDIENTE_2020S000018',\n",
       " 'NEXPEDIENTE_2020S000020',\n",
       " 'NEXPEDIENTE_2020S000021',\n",
       " 'NEXPEDIENTE_2020S000022',\n",
       " 'NEXPEDIENTE_2020S000025',\n",
       " 'NEXPEDIENTE_2020S000030',\n",
       " 'NEXPEDIENTE_2020S000032',\n",
       " 'NEXPEDIENTE_2020S000033',\n",
       " 'NEXPEDIENTE_2020S000035',\n",
       " 'NEXPEDIENTE_2020S000036',\n",
       " 'NEXPEDIENTE_2020S000037',\n",
       " 'NEXPEDIENTE_2020S000038',\n",
       " 'NEXPEDIENTE_2020S000039',\n",
       " 'NEXPEDIENTE_2020S000040',\n",
       " 'NEXPEDIENTE_2020S000042',\n",
       " 'NEXPEDIENTE_2020S000043',\n",
       " 'NEXPEDIENTE_2020S000044',\n",
       " 'NEXPEDIENTE_2020S000045',\n",
       " 'NEXPEDIENTE_2020S000047',\n",
       " 'NEXPEDIENTE_2020S000048',\n",
       " 'NEXPEDIENTE_2020S000049',\n",
       " 'NEXPEDIENTE_2020S000050',\n",
       " 'NEXPEDIENTE_2020S000051',\n",
       " 'NEXPEDIENTE_2020S000053',\n",
       " 'NEXPEDIENTE_2020S000054',\n",
       " 'NEXPEDIENTE_2020S000055',\n",
       " 'NEXPEDIENTE_2020S000056',\n",
       " 'NEXPEDIENTE_2020S000057',\n",
       " 'NEXPEDIENTE_2020S000060',\n",
       " 'NEXPEDIENTE_2020S000061',\n",
       " 'NEXPEDIENTE_2020S000062',\n",
       " 'NEXPEDIENTE_2020S000063',\n",
       " 'NEXPEDIENTE_2020S000064',\n",
       " 'NEXPEDIENTE_2020S000066',\n",
       " 'NEXPEDIENTE_2020S000067',\n",
       " 'NEXPEDIENTE_2020S000070',\n",
       " 'NEXPEDIENTE_2020S000071',\n",
       " 'NEXPEDIENTE_2020S000072',\n",
       " 'NEXPEDIENTE_2020S000073',\n",
       " 'NEXPEDIENTE_2020S000074',\n",
       " 'NEXPEDIENTE_2020S000075',\n",
       " 'NEXPEDIENTE_2020S000076',\n",
       " 'NEXPEDIENTE_2020S000077',\n",
       " 'NEXPEDIENTE_2020S000078',\n",
       " 'NEXPEDIENTE_2020S000079',\n",
       " 'NEXPEDIENTE_2020S000081',\n",
       " 'NEXPEDIENTE_2020S000082',\n",
       " 'NEXPEDIENTE_2020S000083',\n",
       " 'NEXPEDIENTE_2020S000086',\n",
       " 'NEXPEDIENTE_2020S000087',\n",
       " 'NEXPEDIENTE_2020S000088',\n",
       " 'NEXPEDIENTE_2020S000089',\n",
       " 'NEXPEDIENTE_2020S000090',\n",
       " 'NEXPEDIENTE_2020S000091',\n",
       " 'NEXPEDIENTE_2020S000092',\n",
       " 'NEXPEDIENTE_2020S000093',\n",
       " 'NEXPEDIENTE_2020S000095',\n",
       " 'NEXPEDIENTE_2020S000096',\n",
       " 'NEXPEDIENTE_2020S000097',\n",
       " 'NEXPEDIENTE_2020S000098',\n",
       " 'NEXPEDIENTE_2020S000099',\n",
       " 'NEXPEDIENTE_2020S000100',\n",
       " 'NEXPEDIENTE_2020S000102',\n",
       " 'NEXPEDIENTE_2020S000103',\n",
       " 'NEXPEDIENTE_2020S000104',\n",
       " 'NEXPEDIENTE_2020S000105',\n",
       " 'NEXPEDIENTE_2020S000106',\n",
       " 'NEXPEDIENTE_2020S000107',\n",
       " 'NEXPEDIENTE_2020S000108',\n",
       " 'NEXPEDIENTE_2020S000109',\n",
       " 'NEXPEDIENTE_2020S000111',\n",
       " 'NEXPEDIENTE_2020S000112',\n",
       " 'NEXPEDIENTE_2020S000113',\n",
       " 'NEXPEDIENTE_2020S000115',\n",
       " 'NEXPEDIENTE_2020S000116',\n",
       " 'NEXPEDIENTE_2020S000117',\n",
       " 'NEXPEDIENTE_2020S000119',\n",
       " 'NEXPEDIENTE_2020S000123',\n",
       " 'NEXPEDIENTE_2020S000126',\n",
       " 'NEXPEDIENTE_2020S000135',\n",
       " 'NEXPEDIENTE_2020S000136',\n",
       " 'NEXPEDIENTE_2020S000137',\n",
       " 'NEXPEDIENTE_2020S000138',\n",
       " 'NEXPEDIENTE_2020S000139',\n",
       " 'NEXPEDIENTE_2020S000142',\n",
       " 'NEXPEDIENTE_2020S000143',\n",
       " 'NEXPEDIENTE_2020S000144',\n",
       " 'NEXPEDIENTE_2020S000146',\n",
       " 'NEXPEDIENTE_2020S000147',\n",
       " 'NEXPEDIENTE_2020S000148',\n",
       " 'NEXPEDIENTE_2020S000150',\n",
       " 'NEXPEDIENTE_2020S000151',\n",
       " 'NEXPEDIENTE_2020S000152',\n",
       " 'NEXPEDIENTE_2020S000153',\n",
       " 'NEXPEDIENTE_2020S000155',\n",
       " 'NEXPEDIENTE_2020S000157',\n",
       " 'NEXPEDIENTE_2020S000158',\n",
       " 'NEXPEDIENTE_2020S000159',\n",
       " 'NEXPEDIENTE_2020S000160',\n",
       " 'NEXPEDIENTE_2020S000162',\n",
       " 'NEXPEDIENTE_2020S000163',\n",
       " 'NEXPEDIENTE_2020S000165',\n",
       " 'NEXPEDIENTE_2020S000179',\n",
       " 'NEXPEDIENTE_2020S000184',\n",
       " 'NEXPEDIENTE_2020S000185',\n",
       " 'NEXPEDIENTE_2020S000189',\n",
       " 'NEXPEDIENTE_2020S000190',\n",
       " 'NEXPEDIENTE_2020S000192',\n",
       " 'NEXPEDIENTE_2020S000193',\n",
       " 'NEXPEDIENTE_2020S000194',\n",
       " 'NEXPEDIENTE_2020S000195',\n",
       " 'NEXPEDIENTE_2020S000196',\n",
       " 'NEXPEDIENTE_2020S000198',\n",
       " 'NEXPEDIENTE_2020S000201',\n",
       " 'NEXPEDIENTE_2020S000202',\n",
       " 'NEXPEDIENTE_2020S000203',\n",
       " 'NEXPEDIENTE_2020S000204',\n",
       " 'NEXPEDIENTE_2020S000205',\n",
       " 'NEXPEDIENTE_2020S000206',\n",
       " 'NEXPEDIENTE_2020S000207',\n",
       " 'NEXPEDIENTE_2020S000209',\n",
       " 'NEXPEDIENTE_2020S000210',\n",
       " 'NEXPEDIENTE_2020S000211',\n",
       " 'NEXPEDIENTE_2020S000212',\n",
       " 'NEXPEDIENTE_2020S000216',\n",
       " 'NEXPEDIENTE_2020S000217',\n",
       " 'NEXPEDIENTE_2020S000219',\n",
       " 'NEXPEDIENTE_2020S000221',\n",
       " 'NEXPEDIENTE_2020S000222',\n",
       " 'NEXPEDIENTE_2020S000223',\n",
       " 'NEXPEDIENTE_2020S000224',\n",
       " 'NEXPEDIENTE_2020S000225',\n",
       " 'NEXPEDIENTE_2020S000226',\n",
       " 'NEXPEDIENTE_2020S000227',\n",
       " 'NEXPEDIENTE_2020S000229',\n",
       " 'NEXPEDIENTE_2020S000230',\n",
       " 'NEXPEDIENTE_2020S000232',\n",
       " 'NEXPEDIENTE_2020S000233',\n",
       " 'NEXPEDIENTE_2020S000234',\n",
       " 'NEXPEDIENTE_2020S000236',\n",
       " 'NEXPEDIENTE_2020S000237',\n",
       " 'NEXPEDIENTE_2020S000238',\n",
       " 'NEXPEDIENTE_2020S000239',\n",
       " 'NEXPEDIENTE_2020S000240',\n",
       " 'NEXPEDIENTE_2020S000241',\n",
       " 'NEXPEDIENTE_2020S000242',\n",
       " 'NEXPEDIENTE_2020S000243',\n",
       " 'NEXPEDIENTE_2020S000244',\n",
       " 'NEXPEDIENTE_2020S000245',\n",
       " 'NEXPEDIENTE_2020S000250',\n",
       " 'NEXPEDIENTE_2020S000253',\n",
       " 'NEXPEDIENTE_2020S000254',\n",
       " 'NEXPEDIENTE_2020S000255',\n",
       " 'NEXPEDIENTE_2020S000256',\n",
       " 'NEXPEDIENTE_2020S000257',\n",
       " 'NEXPEDIENTE_2020S000258',\n",
       " 'NEXPEDIENTE_2020S000259',\n",
       " 'NEXPEDIENTE_2020S000260',\n",
       " 'NEXPEDIENTE_2020S000261',\n",
       " 'NEXPEDIENTE_2020S000262',\n",
       " 'NEXPEDIENTE_2020S000263',\n",
       " 'NEXPEDIENTE_2020S000264',\n",
       " 'NEXPEDIENTE_2020S000265',\n",
       " 'NEXPEDIENTE_2020S000266',\n",
       " 'NEXPEDIENTE_2020S000267',\n",
       " 'NEXPEDIENTE_2020S000268',\n",
       " 'NEXPEDIENTE_2020S000270',\n",
       " 'NEXPEDIENTE_2020S000271',\n",
       " 'NEXPEDIENTE_2020S000272',\n",
       " 'NEXPEDIENTE_2020S000273',\n",
       " 'NEXPEDIENTE_2020S000274',\n",
       " 'NEXPEDIENTE_2020S000275',\n",
       " 'NEXPEDIENTE_2020S000276',\n",
       " 'NEXPEDIENTE_2020S000278',\n",
       " 'NEXPEDIENTE_2020S000279',\n",
       " 'NEXPEDIENTE_2020S000280',\n",
       " 'NEXPEDIENTE_2020S000282',\n",
       " 'NEXPEDIENTE_2020S000283',\n",
       " 'NEXPEDIENTE_2020S000284',\n",
       " 'NEXPEDIENTE_2020S000285',\n",
       " 'NEXPEDIENTE_2020S000286',\n",
       " 'NEXPEDIENTE_2020S000287',\n",
       " 'NEXPEDIENTE_2020S000288',\n",
       " 'NEXPEDIENTE_2020S000289',\n",
       " 'NEXPEDIENTE_2020S000290',\n",
       " 'NEXPEDIENTE_2020S000291',\n",
       " 'NEXPEDIENTE_2020S000292',\n",
       " 'NEXPEDIENTE_2020S000293',\n",
       " 'NEXPEDIENTE_2020S000294',\n",
       " 'NEXPEDIENTE_2020S000295',\n",
       " 'NEXPEDIENTE_2020S000296',\n",
       " 'NEXPEDIENTE_2020S000297',\n",
       " 'NEXPEDIENTE_2020S000299',\n",
       " 'NEXPEDIENTE_2020S000300',\n",
       " 'NEXPEDIENTE_2020S000301',\n",
       " 'NEXPEDIENTE_2020S000302',\n",
       " 'NEXPEDIENTE_2020S000303',\n",
       " 'NEXPEDIENTE_2020S000304',\n",
       " 'NEXPEDIENTE_2020S000305',\n",
       " 'NEXPEDIENTE_2020S000306',\n",
       " 'NEXPEDIENTE_2020S000307',\n",
       " 'NEXPEDIENTE_2020S000309',\n",
       " 'NEXPEDIENTE_2020S000310',\n",
       " 'NEXPEDIENTE_2020S000311',\n",
       " 'NEXPEDIENTE_2020S000312',\n",
       " 'NEXPEDIENTE_2020S000313',\n",
       " 'NEXPEDIENTE_2020S000314',\n",
       " 'NEXPEDIENTE_2020S000315',\n",
       " 'NEXPEDIENTE_2020S000316',\n",
       " 'NEXPEDIENTE_2020S000317',\n",
       " 'NEXPEDIENTE_2020S000318',\n",
       " 'NEXPEDIENTE_2020S000319',\n",
       " 'NEXPEDIENTE_2020S000320',\n",
       " 'NEXPEDIENTE_2020S000321',\n",
       " 'NEXPEDIENTE_2020S000322',\n",
       " 'NEXPEDIENTE_2020S000323',\n",
       " 'NEXPEDIENTE_2020S000324',\n",
       " 'NEXPEDIENTE_2020S000325',\n",
       " 'NEXPEDIENTE_2020S000326',\n",
       " 'NEXPEDIENTE_2020S000327',\n",
       " 'NEXPEDIENTE_2020S000328',\n",
       " 'NEXPEDIENTE_2020S000329',\n",
       " 'NEXPEDIENTE_2020S000330',\n",
       " 'NEXPEDIENTE_2020S000331',\n",
       " 'NEXPEDIENTE_2020S000332',\n",
       " 'NEXPEDIENTE_2020S000333',\n",
       " 'NEXPEDIENTE_2020S000334',\n",
       " 'NEXPEDIENTE_2020S000335',\n",
       " 'NEXPEDIENTE_2020S000336',\n",
       " 'NEXPEDIENTE_2020S000337',\n",
       " 'NEXPEDIENTE_2020S000338',\n",
       " 'NEXPEDIENTE_2020S000340',\n",
       " 'NEXPEDIENTE_2020S000341',\n",
       " 'NEXPEDIENTE_2020S000342',\n",
       " 'NEXPEDIENTE_2020S000344',\n",
       " 'NEXPEDIENTE_2020S000345',\n",
       " 'NEXPEDIENTE_2020S000346',\n",
       " 'NEXPEDIENTE_2020S000347',\n",
       " 'NEXPEDIENTE_2020S000348',\n",
       " 'NEXPEDIENTE_2020S000349',\n",
       " 'NEXPEDIENTE_2020S000350',\n",
       " 'NEXPEDIENTE_2020S000351',\n",
       " 'NEXPEDIENTE_2020S000352',\n",
       " 'NEXPEDIENTE_2020S000354',\n",
       " 'NEXPEDIENTE_2020S000355',\n",
       " 'NEXPEDIENTE_2020S000356',\n",
       " 'NEXPEDIENTE_2020S000357',\n",
       " 'NEXPEDIENTE_2020S000358',\n",
       " 'NEXPEDIENTE_2020S000359',\n",
       " 'NEXPEDIENTE_2020S000360',\n",
       " 'NEXPEDIENTE_2020S000362',\n",
       " 'NEXPEDIENTE_2020S000363',\n",
       " 'NEXPEDIENTE_2020S000364',\n",
       " 'NEXPEDIENTE_2020S000365',\n",
       " 'NEXPEDIENTE_2020S000366',\n",
       " 'NEXPEDIENTE_2020S000367',\n",
       " 'NEXPEDIENTE_2020S000368',\n",
       " 'NEXPEDIENTE_2020S000369',\n",
       " 'NEXPEDIENTE_2020S000370',\n",
       " 'NEXPEDIENTE_2020S000371',\n",
       " 'NEXPEDIENTE_2020S000372',\n",
       " 'NEXPEDIENTE_2020S000373',\n",
       " 'NEXPEDIENTE_2020S000374',\n",
       " 'NEXPEDIENTE_2020S000375',\n",
       " 'NEXPEDIENTE_2020S000376',\n",
       " 'NEXPEDIENTE_2020S000378',\n",
       " 'NEXPEDIENTE_2020S000380',\n",
       " 'NEXPEDIENTE_2020S000381',\n",
       " 'NEXPEDIENTE_2020S000382',\n",
       " 'NEXPEDIENTE_2020S000383',\n",
       " 'NEXPEDIENTE_2020S000384',\n",
       " 'NEXPEDIENTE_2020S000385',\n",
       " 'NEXPEDIENTE_2020S000386',\n",
       " 'NEXPEDIENTE_2020S000387',\n",
       " 'NEXPEDIENTE_2020S000388',\n",
       " 'NEXPEDIENTE_2020S000389',\n",
       " 'NEXPEDIENTE_2020S000390',\n",
       " 'NEXPEDIENTE_2020S000391',\n",
       " 'NEXPEDIENTE_2020S000392',\n",
       " 'NEXPEDIENTE_2020S000393',\n",
       " 'NEXPEDIENTE_2020S000394',\n",
       " 'NEXPEDIENTE_2020S000395',\n",
       " 'NEXPEDIENTE_2020S000396',\n",
       " 'NEXPEDIENTE_2020S000397',\n",
       " 'NEXPEDIENTE_2020S000398',\n",
       " 'NEXPEDIENTE_2020S000399',\n",
       " 'NEXPEDIENTE_2020S000400',\n",
       " 'NEXPEDIENTE_2020S000401',\n",
       " 'NEXPEDIENTE_2020S000402',\n",
       " 'NEXPEDIENTE_2020S000403',\n",
       " 'NEXPEDIENTE_2020S000406',\n",
       " 'NEXPEDIENTE_2020S000407',\n",
       " 'NEXPEDIENTE_2020S000409',\n",
       " 'NEXPEDIENTE_2020S000410',\n",
       " 'NEXPEDIENTE_2020S000411',\n",
       " 'NEXPEDIENTE_2020S000412',\n",
       " 'NEXPEDIENTE_2020S000413',\n",
       " 'NEXPEDIENTE_2020S000414',\n",
       " 'NEXPEDIENTE_2020S000415',\n",
       " 'NEXPEDIENTE_2020S000416',\n",
       " 'NEXPEDIENTE_2020S000417',\n",
       " 'NEXPEDIENTE_2020S000418',\n",
       " 'NEXPEDIENTE_2020S000420',\n",
       " 'NEXPEDIENTE_2020S000421',\n",
       " 'NEXPEDIENTE_2020S000422',\n",
       " 'NEXPEDIENTE_2020S000423',\n",
       " 'NEXPEDIENTE_2020S000424',\n",
       " 'NEXPEDIENTE_2020S000425',\n",
       " 'NEXPEDIENTE_2020S000426',\n",
       " 'NEXPEDIENTE_2020S000427',\n",
       " 'NEXPEDIENTE_2020S000428',\n",
       " 'NEXPEDIENTE_2020S000430',\n",
       " 'NEXPEDIENTE_2020S000431',\n",
       " 'NEXPEDIENTE_2020S000432',\n",
       " 'NEXPEDIENTE_2020S000433',\n",
       " 'NEXPEDIENTE_2020S000434',\n",
       " 'NEXPEDIENTE_2020S000435',\n",
       " 'NEXPEDIENTE_2020S000436',\n",
       " 'NEXPEDIENTE_2020S000437',\n",
       " 'NEXPEDIENTE_2020S000438',\n",
       " 'NEXPEDIENTE_2020S000439',\n",
       " 'NEXPEDIENTE_2020S000440',\n",
       " 'NEXPEDIENTE_2020S000441',\n",
       " 'NEXPEDIENTE_2020S000443',\n",
       " 'NEXPEDIENTE_2020S000444',\n",
       " 'NEXPEDIENTE_2020S000445',\n",
       " 'NEXPEDIENTE_2020S000446',\n",
       " 'NEXPEDIENTE_2020S000447',\n",
       " 'NEXPEDIENTE_2020S000448',\n",
       " 'NEXPEDIENTE_2020S000449',\n",
       " 'NEXPEDIENTE_2020S000450',\n",
       " 'NEXPEDIENTE_2020S000451',\n",
       " 'NEXPEDIENTE_2020S000452',\n",
       " 'NEXPEDIENTE_2020S000453',\n",
       " 'NEXPEDIENTE_2020S000454',\n",
       " 'NEXPEDIENTE_2020S000455',\n",
       " 'NEXPEDIENTE_2020S000456',\n",
       " 'NEXPEDIENTE_2020S000457',\n",
       " 'NEXPEDIENTE_2020S000458',\n",
       " 'NEXPEDIENTE_2020S000460',\n",
       " 'NEXPEDIENTE_2020S000462',\n",
       " 'NEXPEDIENTE_2020S000463',\n",
       " 'NEXPEDIENTE_2020S000464',\n",
       " 'NEXPEDIENTE_2020S000465',\n",
       " 'NEXPEDIENTE_2020S000466',\n",
       " 'NEXPEDIENTE_2020S000467',\n",
       " 'NEXPEDIENTE_2020S000469',\n",
       " 'NEXPEDIENTE_2020S000470',\n",
       " 'NEXPEDIENTE_2020S000471',\n",
       " 'NEXPEDIENTE_2020S000472',\n",
       " 'NEXPEDIENTE_2020S000473',\n",
       " 'NEXPEDIENTE_2020S000474',\n",
       " 'NEXPEDIENTE_2020S000475',\n",
       " 'NEXPEDIENTE_2020S000477',\n",
       " 'NEXPEDIENTE_2020S000478',\n",
       " 'NEXPEDIENTE_2020S000479',\n",
       " 'NEXPEDIENTE_2020S000480',\n",
       " 'NEXPEDIENTE_2020S000482',\n",
       " 'NEXPEDIENTE_2020S000487',\n",
       " 'NEXPEDIENTE_2020S000490',\n",
       " 'NEXPEDIENTE_2020S000491',\n",
       " 'NEXPEDIENTE_2020S000492',\n",
       " 'NEXPEDIENTE_2020S000493',\n",
       " 'NEXPEDIENTE_2020S000494',\n",
       " 'NEXPEDIENTE_2020S000495',\n",
       " 'NEXPEDIENTE_2020S000496',\n",
       " 'NEXPEDIENTE_2020S000497',\n",
       " 'NEXPEDIENTE_2020S000498',\n",
       " 'NEXPEDIENTE_2020S000499',\n",
       " 'NEXPEDIENTE_2020S000500',\n",
       " 'NEXPEDIENTE_2020S000502',\n",
       " 'NEXPEDIENTE_2020S000503',\n",
       " 'NEXPEDIENTE_2020S000504',\n",
       " 'NEXPEDIENTE_2020S000505',\n",
       " 'NEXPEDIENTE_2020S000506',\n",
       " 'NEXPEDIENTE_2020S000508',\n",
       " 'NEXPEDIENTE_2020S000510',\n",
       " 'NEXPEDIENTE_2020S000511',\n",
       " 'NEXPEDIENTE_2020S000512',\n",
       " 'NEXPEDIENTE_2020S000514',\n",
       " 'NEXPEDIENTE_2020S000515',\n",
       " 'NEXPEDIENTE_2020S000516',\n",
       " 'NEXPEDIENTE_2020S000517',\n",
       " 'NEXPEDIENTE_2020S000518',\n",
       " 'NEXPEDIENTE_2020S000519',\n",
       " 'NEXPEDIENTE_2020S000520',\n",
       " 'NEXPEDIENTE_2020S000521',\n",
       " 'NEXPEDIENTE_2020S000522',\n",
       " 'NEXPEDIENTE_2020S000523',\n",
       " 'NEXPEDIENTE_2020S000524',\n",
       " 'NEXPEDIENTE_2020S000525',\n",
       " 'NEXPEDIENTE_2020S000526',\n",
       " 'NEXPEDIENTE_2020S000527',\n",
       " 'NEXPEDIENTE_2020S000528',\n",
       " 'NEXPEDIENTE_2020S000530',\n",
       " 'NEXPEDIENTE_2020S000531',\n",
       " 'NEXPEDIENTE_2020S000532',\n",
       " 'NEXPEDIENTE_2020S000533',\n",
       " 'NEXPEDIENTE_2020S000534',\n",
       " 'NEXPEDIENTE_2020S000535',\n",
       " 'NEXPEDIENTE_2020S000536',\n",
       " 'NEXPEDIENTE_2020S000539',\n",
       " 'NEXPEDIENTE_2020S000540',\n",
       " 'NEXPEDIENTE_2020S000541',\n",
       " 'NEXPEDIENTE_2020S000542',\n",
       " 'NEXPEDIENTE_2020S000543',\n",
       " 'NEXPEDIENTE_2020S000545',\n",
       " 'NEXPEDIENTE_2020S000546',\n",
       " 'NEXPEDIENTE_2020S000547',\n",
       " 'NEXPEDIENTE_2020S000548',\n",
       " 'NEXPEDIENTE_2020S000549',\n",
       " 'NEXPEDIENTE_2020S000550',\n",
       " 'NEXPEDIENTE_2020S000551',\n",
       " 'NEXPEDIENTE_2020S000552',\n",
       " 'NEXPEDIENTE_2020S000553',\n",
       " 'NEXPEDIENTE_2020S000557',\n",
       " 'NEXPEDIENTE_2020S000559',\n",
       " 'NEXPEDIENTE_2020S000560',\n",
       " 'NEXPEDIENTE_2020S000562',\n",
       " 'NEXPEDIENTE_2020S000563',\n",
       " 'NEXPEDIENTE_2020S000571',\n",
       " 'NEXPEDIENTE_2020S000573',\n",
       " 'NEXPEDIENTE_2020S000582',\n",
       " 'NEXPEDIENTE_2020S000583',\n",
       " 'NEXPEDIENTE_2020S000584',\n",
       " 'NEXPEDIENTE_2020S000585',\n",
       " 'NEXPEDIENTE_2020S000586',\n",
       " 'NEXPEDIENTE_2020S000587',\n",
       " 'NEXPEDIENTE_2020S000589',\n",
       " 'NEXPEDIENTE_2020S000591',\n",
       " 'NEXPEDIENTE_2020S000592',\n",
       " 'NEXPEDIENTE_2020S000593',\n",
       " 'NEXPEDIENTE_2020S000595',\n",
       " 'NEXPEDIENTE_2020S000599',\n",
       " 'NEXPEDIENTE_2020S000600',\n",
       " 'NEXPEDIENTE_2020S000601',\n",
       " 'NEXPEDIENTE_2020S000603',\n",
       " 'NEXPEDIENTE_2020S000604',\n",
       " 'NEXPEDIENTE_2020S000605',\n",
       " 'NEXPEDIENTE_2020S000606',\n",
       " 'NEXPEDIENTE_2020S000607',\n",
       " 'NEXPEDIENTE_2020S000608',\n",
       " 'NEXPEDIENTE_2020S000609',\n",
       " 'NEXPEDIENTE_2020S000610',\n",
       " 'NEXPEDIENTE_2020S000611',\n",
       " 'NEXPEDIENTE_2020S000612',\n",
       " 'NEXPEDIENTE_2020S000613',\n",
       " 'NEXPEDIENTE_2020S000614',\n",
       " 'NEXPEDIENTE_2020S000615',\n",
       " 'NEXPEDIENTE_2020S000616',\n",
       " 'NEXPEDIENTE_2020S000617',\n",
       " 'NEXPEDIENTE_2020S000619',\n",
       " 'NEXPEDIENTE_2020S000620',\n",
       " 'NEXPEDIENTE_2020S000621',\n",
       " 'NEXPEDIENTE_2020S000622',\n",
       " 'NEXPEDIENTE_2020S000623',\n",
       " 'NEXPEDIENTE_2020S000625',\n",
       " 'NEXPEDIENTE_2020S000626',\n",
       " 'NEXPEDIENTE_2020S000627',\n",
       " 'NEXPEDIENTE_2020S000628',\n",
       " 'NEXPEDIENTE_2020S000629',\n",
       " 'NEXPEDIENTE_2020S000630',\n",
       " 'NEXPEDIENTE_2020S000631',\n",
       " 'NEXPEDIENTE_2020S000633',\n",
       " 'NEXPEDIENTE_2020S000634',\n",
       " 'NEXPEDIENTE_2020S000635',\n",
       " 'NEXPEDIENTE_2020S000636',\n",
       " 'NEXPEDIENTE_2020S000642',\n",
       " 'NEXPEDIENTE_2020S000643',\n",
       " 'NEXPEDIENTE_2020S000645',\n",
       " 'NEXPEDIENTE_2020S000646',\n",
       " 'NEXPEDIENTE_2020S000647',\n",
       " 'NEXPEDIENTE_2020S000648',\n",
       " 'NEXPEDIENTE_2020S000651',\n",
       " 'NEXPEDIENTE_2020S000653',\n",
       " 'NEXPEDIENTE_2020S000654',\n",
       " 'NEXPEDIENTE_2020S000655',\n",
       " 'NEXPEDIENTE_2020S000656',\n",
       " 'NEXPEDIENTE_2020S000657',\n",
       " 'NEXPEDIENTE_2020S000658',\n",
       " 'NEXPEDIENTE_2020S000660',\n",
       " 'NEXPEDIENTE_2020S000664',\n",
       " 'NEXPEDIENTE_2020S000665',\n",
       " 'NEXPEDIENTE_2020S000666',\n",
       " 'NEXPEDIENTE_2020S000667',\n",
       " 'NEXPEDIENTE_2020S000668',\n",
       " 'NEXPEDIENTE_2020S000669',\n",
       " 'NEXPEDIENTE_2020S000670',\n",
       " 'NEXPEDIENTE_2020S000671',\n",
       " 'NEXPEDIENTE_2020S000673',\n",
       " 'NEXPEDIENTE_2020S000674',\n",
       " 'NEXPEDIENTE_2020S000676',\n",
       " 'NEXPEDIENTE_2020S000677',\n",
       " 'NEXPEDIENTE_2020S000678',\n",
       " 'NEXPEDIENTE_2020S000679',\n",
       " 'NEXPEDIENTE_2020S000680',\n",
       " 'NEXPEDIENTE_2020S000683',\n",
       " 'NEXPEDIENTE_2020S000684',\n",
       " 'NEXPEDIENTE_2020S000685',\n",
       " 'NEXPEDIENTE_2020S000686',\n",
       " 'NEXPEDIENTE_2020S000687',\n",
       " 'NEXPEDIENTE_2020S000689',\n",
       " 'NEXPEDIENTE_2020S000690',\n",
       " 'NEXPEDIENTE_2020S000691',\n",
       " 'NEXPEDIENTE_2020S000692',\n",
       " 'NEXPEDIENTE_2020S000693',\n",
       " 'NEXPEDIENTE_2020S000694',\n",
       " 'NEXPEDIENTE_2020S000695',\n",
       " 'NEXPEDIENTE_2020S000696',\n",
       " 'NEXPEDIENTE_2020S000698',\n",
       " 'NEXPEDIENTE_2020S000699',\n",
       " 'NEXPEDIENTE_2020S000700',\n",
       " 'NEXPEDIENTE_2020S000701',\n",
       " 'NEXPEDIENTE_2020S000704',\n",
       " 'NEXPEDIENTE_2020S000705',\n",
       " 'NEXPEDIENTE_2020S000706',\n",
       " 'NEXPEDIENTE_2020S000707',\n",
       " 'NEXPEDIENTE_2020S000708',\n",
       " 'NEXPEDIENTE_2020S000709',\n",
       " 'NEXPEDIENTE_2020S000712',\n",
       " 'NEXPEDIENTE_2020S000713',\n",
       " 'NEXPEDIENTE_2020S000715',\n",
       " 'NEXPEDIENTE_2020S000716',\n",
       " 'NEXPEDIENTE_2020S000717',\n",
       " 'NEXPEDIENTE_2020S000718',\n",
       " 'NEXPEDIENTE_2020S000719',\n",
       " 'NEXPEDIENTE_2020S000720',\n",
       " 'NEXPEDIENTE_2020S000721',\n",
       " 'NEXPEDIENTE_2020S000722',\n",
       " 'NEXPEDIENTE_2020S000723',\n",
       " 'NEXPEDIENTE_2020S000725',\n",
       " 'NEXPEDIENTE_2020S000726',\n",
       " 'NEXPEDIENTE_2020S000728',\n",
       " 'NEXPEDIENTE_2020S000729',\n",
       " 'NEXPEDIENTE_2020S000731',\n",
       " 'NEXPEDIENTE_2020S000732',\n",
       " 'NEXPEDIENTE_2020S000735',\n",
       " 'NEXPEDIENTE_2020S000736',\n",
       " 'NEXPEDIENTE_2020S000737',\n",
       " 'NEXPEDIENTE_2020S000738',\n",
       " 'NEXPEDIENTE_2020S000739',\n",
       " 'NEXPEDIENTE_2020S000740',\n",
       " 'NEXPEDIENTE_2020S000741',\n",
       " 'NEXPEDIENTE_2020S000742',\n",
       " 'NEXPEDIENTE_2020S000743',\n",
       " 'NEXPEDIENTE_2020S000744',\n",
       " 'NEXPEDIENTE_2020S000745',\n",
       " 'NEXPEDIENTE_2020S000746',\n",
       " 'NEXPEDIENTE_2020S000747',\n",
       " 'NEXPEDIENTE_2020S000748',\n",
       " 'NEXPEDIENTE_2020S000749',\n",
       " 'NEXPEDIENTE_2020S000750',\n",
       " 'NEXPEDIENTE_2020S000751',\n",
       " 'NEXPEDIENTE_2020S000753',\n",
       " 'NEXPEDIENTE_2020S000756',\n",
       " 'NEXPEDIENTE_2020S000758',\n",
       " 'NEXPEDIENTE_2020S000759',\n",
       " 'NEXPEDIENTE_2020S000761',\n",
       " 'NEXPEDIENTE_2020S000762',\n",
       " 'NEXPEDIENTE_2020S000765',\n",
       " 'NEXPEDIENTE_2020S000767',\n",
       " 'NEXPEDIENTE_2020S000769',\n",
       " 'NEXPEDIENTE_2020S000770',\n",
       " 'NEXPEDIENTE_2020S000771',\n",
       " 'NEXPEDIENTE_2020S000772',\n",
       " 'NEXPEDIENTE_2020S000773',\n",
       " 'NEXPEDIENTE_2020S000774',\n",
       " 'NEXPEDIENTE_2020S000775',\n",
       " 'NEXPEDIENTE_2020S000776',\n",
       " 'NEXPEDIENTE_2020S000777',\n",
       " 'NEXPEDIENTE_2020S000778',\n",
       " 'NEXPEDIENTE_2020S000779',\n",
       " 'NEXPEDIENTE_2020S000782',\n",
       " 'NEXPEDIENTE_2020S000784',\n",
       " 'NEXPEDIENTE_2020S000786',\n",
       " 'NEXPEDIENTE_2020S000787',\n",
       " 'NEXPEDIENTE_2020S000788',\n",
       " 'NEXPEDIENTE_2020S000789',\n",
       " 'NEXPEDIENTE_2020S000791',\n",
       " 'NEXPEDIENTE_2020S000792',\n",
       " 'NEXPEDIENTE_2020S000793',\n",
       " 'NEXPEDIENTE_2020S000794',\n",
       " 'NEXPEDIENTE_2020S000795',\n",
       " 'NEXPEDIENTE_2020S000796',\n",
       " 'NEXPEDIENTE_2020S000797',\n",
       " 'NEXPEDIENTE_2020S000798',\n",
       " 'NEXPEDIENTE_2020S000799',\n",
       " 'NEXPEDIENTE_2020S000801',\n",
       " 'NEXPEDIENTE_2020S000802',\n",
       " 'NEXPEDIENTE_2020S000803',\n",
       " 'NEXPEDIENTE_2020S000804',\n",
       " 'NEXPEDIENTE_2020S000805',\n",
       " 'NEXPEDIENTE_2020S000806',\n",
       " 'NEXPEDIENTE_2020S000807',\n",
       " 'NEXPEDIENTE_2020S000808',\n",
       " 'NEXPEDIENTE_2020S000809',\n",
       " 'NEXPEDIENTE_2020S000810',\n",
       " 'NEXPEDIENTE_2020S000811',\n",
       " 'NEXPEDIENTE_2020S000815',\n",
       " 'NEXPEDIENTE_2020S000816',\n",
       " 'NEXPEDIENTE_2020S000817',\n",
       " 'NEXPEDIENTE_2020S000818',\n",
       " 'NEXPEDIENTE_2020S000819',\n",
       " 'NEXPEDIENTE_2020S000820',\n",
       " 'NEXPEDIENTE_2020S000821',\n",
       " 'NEXPEDIENTE_2020S000822',\n",
       " 'NEXPEDIENTE_2020S000824',\n",
       " 'NEXPEDIENTE_2020S000825',\n",
       " 'NEXPEDIENTE_2020S000826',\n",
       " 'NEXPEDIENTE_2020S000827',\n",
       " 'NEXPEDIENTE_2020S000830',\n",
       " 'NEXPEDIENTE_2020S000831',\n",
       " 'NEXPEDIENTE_2020S000832',\n",
       " 'NEXPEDIENTE_2020S000833',\n",
       " 'NEXPEDIENTE_2020S000834',\n",
       " 'NEXPEDIENTE_2020S000835',\n",
       " 'NEXPEDIENTE_2020S000836',\n",
       " 'NEXPEDIENTE_2020S000837',\n",
       " 'NEXPEDIENTE_2020S000838',\n",
       " 'NEXPEDIENTE_2020S000839',\n",
       " 'NEXPEDIENTE_2020S000840',\n",
       " 'NEXPEDIENTE_2020S000841',\n",
       " 'NEXPEDIENTE_2020S000842',\n",
       " 'NEXPEDIENTE_2020S000843',\n",
       " 'NEXPEDIENTE_2020S000846',\n",
       " 'NEXPEDIENTE_2020S000847',\n",
       " 'NEXPEDIENTE_2020S000849',\n",
       " 'NEXPEDIENTE_2020S000850',\n",
       " 'NEXPEDIENTE_2020S000851',\n",
       " 'NEXPEDIENTE_2020S000853',\n",
       " 'NEXPEDIENTE_2020S000854',\n",
       " 'NEXPEDIENTE_2020S000855',\n",
       " 'NEXPEDIENTE_2020S000856',\n",
       " 'NEXPEDIENTE_2020S000857',\n",
       " 'NEXPEDIENTE_2020S000858',\n",
       " 'NEXPEDIENTE_2020S000859',\n",
       " 'NEXPEDIENTE_2020S000860',\n",
       " 'NEXPEDIENTE_2020S000861',\n",
       " 'NEXPEDIENTE_2020S000862',\n",
       " 'NEXPEDIENTE_2020S000863',\n",
       " 'NEXPEDIENTE_2020S000864',\n",
       " 'NEXPEDIENTE_2020S000866',\n",
       " 'NEXPEDIENTE_2020S000867',\n",
       " 'NEXPEDIENTE_2020S000868',\n",
       " 'NEXPEDIENTE_2020S000869',\n",
       " 'NEXPEDIENTE_2020S000871',\n",
       " 'NEXPEDIENTE_2020S000872',\n",
       " 'NEXPEDIENTE_2020S000873',\n",
       " 'NEXPEDIENTE_2020S000876',\n",
       " 'NEXPEDIENTE_2020S000877',\n",
       " 'NEXPEDIENTE_2020S000878',\n",
       " 'NEXPEDIENTE_2020S000879',\n",
       " 'NEXPEDIENTE_2020S000880',\n",
       " 'NEXPEDIENTE_2020S000881',\n",
       " 'NEXPEDIENTE_2020S000883',\n",
       " 'NEXPEDIENTE_2020S000884',\n",
       " 'NEXPEDIENTE_2020S000885',\n",
       " 'NEXPEDIENTE_2020S000887',\n",
       " 'NEXPEDIENTE_2020S000888',\n",
       " 'NEXPEDIENTE_2020S000889',\n",
       " 'NEXPEDIENTE_2020S000890',\n",
       " 'NEXPEDIENTE_2020S000891',\n",
       " 'NEXPEDIENTE_2020S000892',\n",
       " 'NEXPEDIENTE_2020S000893',\n",
       " 'NEXPEDIENTE_2020S000894',\n",
       " 'NEXPEDIENTE_2020S000896',\n",
       " 'NEXPEDIENTE_2020S000897',\n",
       " 'NEXPEDIENTE_2020S000898',\n",
       " 'NEXPEDIENTE_2020S000899',\n",
       " 'NEXPEDIENTE_2020S000900',\n",
       " 'NEXPEDIENTE_2020S000903',\n",
       " 'NEXPEDIENTE_2020S000904',\n",
       " 'NEXPEDIENTE_2020S000905',\n",
       " 'NEXPEDIENTE_2020S000907',\n",
       " 'NEXPEDIENTE_2020S000908',\n",
       " 'NEXPEDIENTE_2020S000909',\n",
       " 'NEXPEDIENTE_2020S000910',\n",
       " 'NEXPEDIENTE_2020S000911',\n",
       " 'NEXPEDIENTE_2020S000912',\n",
       " 'NEXPEDIENTE_2020S000913',\n",
       " 'NEXPEDIENTE_2020S000914',\n",
       " 'NEXPEDIENTE_2020S000915',\n",
       " 'NEXPEDIENTE_2020S000916',\n",
       " 'NEXPEDIENTE_2020S000918',\n",
       " 'NEXPEDIENTE_2020S000919',\n",
       " 'NEXPEDIENTE_2020S000920',\n",
       " 'NEXPEDIENTE_2020S000921',\n",
       " 'NEXPEDIENTE_2020S000922',\n",
       " 'NEXPEDIENTE_2020S000925',\n",
       " 'NEXPEDIENTE_2020S000926',\n",
       " 'NEXPEDIENTE_2020S000927',\n",
       " 'NEXPEDIENTE_2020S000928',\n",
       " 'NEXPEDIENTE_2020S000929',\n",
       " 'NEXPEDIENTE_2020S000930',\n",
       " 'NEXPEDIENTE_2020S000931',\n",
       " 'NEXPEDIENTE_2020S000932',\n",
       " 'NEXPEDIENTE_2020S000933',\n",
       " 'NEXPEDIENTE_2020S000934',\n",
       " 'NEXPEDIENTE_2020S000935',\n",
       " 'NEXPEDIENTE_2020S000936',\n",
       " 'NEXPEDIENTE_2020S000938',\n",
       " 'NEXPEDIENTE_2020S000939',\n",
       " 'NEXPEDIENTE_2020S000940',\n",
       " 'NEXPEDIENTE_2020S000942',\n",
       " 'NEXPEDIENTE_2020S000943',\n",
       " 'NEXPEDIENTE_2020S000945',\n",
       " 'NEXPEDIENTE_2020S000947',\n",
       " 'NEXPEDIENTE_2020S000948',\n",
       " 'NEXPEDIENTE_2020S000950',\n",
       " 'NEXPEDIENTE_2020S000951',\n",
       " 'NEXPEDIENTE_2020S000952',\n",
       " 'NEXPEDIENTE_2020S000953',\n",
       " 'NEXPEDIENTE_2020S000954',\n",
       " 'NEXPEDIENTE_2020S000956',\n",
       " 'NEXPEDIENTE_2020S000957',\n",
       " 'NEXPEDIENTE_2020S000958',\n",
       " 'NEXPEDIENTE_2020S000959',\n",
       " 'NEXPEDIENTE_2020S000960',\n",
       " 'NEXPEDIENTE_2020S000961',\n",
       " 'NEXPEDIENTE_2020S000962',\n",
       " 'NEXPEDIENTE_2020S000963',\n",
       " 'NEXPEDIENTE_2020S000964',\n",
       " 'NEXPEDIENTE_2020S000965',\n",
       " 'NEXPEDIENTE_2020S000966',\n",
       " 'NEXPEDIENTE_2020S000967',\n",
       " 'NEXPEDIENTE_2020S000968',\n",
       " 'NEXPEDIENTE_2020S000969',\n",
       " 'NEXPEDIENTE_2020S000970',\n",
       " 'NEXPEDIENTE_2020S000972',\n",
       " 'NEXPEDIENTE_2020S000976',\n",
       " 'NEXPEDIENTE_2020S000978',\n",
       " 'NEXPEDIENTE_2020S000979',\n",
       " 'NEXPEDIENTE_2020S000980',\n",
       " 'NEXPEDIENTE_2020S000981',\n",
       " 'NEXPEDIENTE_2020S000982',\n",
       " 'NEXPEDIENTE_2020S000983',\n",
       " 'NEXPEDIENTE_2020S000984',\n",
       " 'NEXPEDIENTE_2020S000985',\n",
       " 'NEXPEDIENTE_2020S000986',\n",
       " 'NEXPEDIENTE_2020S000987',\n",
       " 'NEXPEDIENTE_2020S000988',\n",
       " 'NEXPEDIENTE_2020S000989',\n",
       " 'NEXPEDIENTE_2020S000990',\n",
       " 'NEXPEDIENTE_2020S000991',\n",
       " 'NEXPEDIENTE_2020S000992',\n",
       " 'NEXPEDIENTE_2020S000993',\n",
       " 'NEXPEDIENTE_2020S000994',\n",
       " 'NEXPEDIENTE_2020S000995',\n",
       " 'NEXPEDIENTE_2020S000996',\n",
       " 'NEXPEDIENTE_2020S000997',\n",
       " 'NEXPEDIENTE_2020S000998',\n",
       " 'NEXPEDIENTE_2020S000999',\n",
       " 'NEXPEDIENTE_2020S001001',\n",
       " 'NEXPEDIENTE_2020S001002',\n",
       " 'NEXPEDIENTE_2020S001003',\n",
       " 'NEXPEDIENTE_2020S001004',\n",
       " 'NEXPEDIENTE_2020S001005',\n",
       " 'NEXPEDIENTE_2020S001008',\n",
       " 'NEXPEDIENTE_2020S001010',\n",
       " 'NEXPEDIENTE_2020S001012',\n",
       " 'NEXPEDIENTE_2020S001013',\n",
       " 'NEXPEDIENTE_2020S001017',\n",
       " 'NEXPEDIENTE_2020S001019',\n",
       " 'NEXPEDIENTE_2020S001021',\n",
       " 'NEXPEDIENTE_2020S001023',\n",
       " 'NEXPEDIENTE_2020S001024',\n",
       " 'NEXPEDIENTE_2020S001025',\n",
       " 'NEXPEDIENTE_2020S001027',\n",
       " 'NEXPEDIENTE_2020S001028',\n",
       " 'NEXPEDIENTE_2020S001030',\n",
       " 'NEXPEDIENTE_2020S001031',\n",
       " 'NEXPEDIENTE_2020S001032',\n",
       " 'NEXPEDIENTE_2020S001034',\n",
       " 'NEXPEDIENTE_2020S001035',\n",
       " 'NEXPEDIENTE_2020S001037',\n",
       " 'NEXPEDIENTE_2020S001038',\n",
       " 'NEXPEDIENTE_2020S001039',\n",
       " 'NEXPEDIENTE_2020S001040',\n",
       " 'NEXPEDIENTE_2020S001041',\n",
       " 'NEXPEDIENTE_2020S001042',\n",
       " 'NEXPEDIENTE_2020S001043',\n",
       " 'NEXPEDIENTE_2020S001044',\n",
       " 'NEXPEDIENTE_2020S001045',\n",
       " 'NEXPEDIENTE_2020S001047',\n",
       " 'NEXPEDIENTE_2020S001048',\n",
       " 'NEXPEDIENTE_2020S001049',\n",
       " 'NEXPEDIENTE_2020S001051',\n",
       " 'NEXPEDIENTE_2020S001052',\n",
       " 'NEXPEDIENTE_2020S001053',\n",
       " 'NEXPEDIENTE_2020S001054',\n",
       " 'NEXPEDIENTE_2020S001056',\n",
       " 'NEXPEDIENTE_2020S001057',\n",
       " 'NEXPEDIENTE_2020S001058',\n",
       " 'NEXPEDIENTE_2020S001060',\n",
       " 'NEXPEDIENTE_2020S001061',\n",
       " 'NEXPEDIENTE_2020S001062',\n",
       " 'NEXPEDIENTE_2020S001063',\n",
       " 'NEXPEDIENTE_2020S001064',\n",
       " 'NEXPEDIENTE_2020S001067',\n",
       " 'NEXPEDIENTE_2020S001068',\n",
       " 'NEXPEDIENTE_2020S001069',\n",
       " 'NEXPEDIENTE_2020S001070',\n",
       " 'NEXPEDIENTE_2020S001071',\n",
       " 'NEXPEDIENTE_2020S001072',\n",
       " 'NEXPEDIENTE_2020S001073',\n",
       " 'NEXPEDIENTE_2020S001074',\n",
       " 'NEXPEDIENTE_2020S001076',\n",
       " 'NEXPEDIENTE_2020S001077',\n",
       " 'NEXPEDIENTE_2020S001078',\n",
       " 'NEXPEDIENTE_2020S001079',\n",
       " 'NEXPEDIENTE_2020S001082',\n",
       " 'NEXPEDIENTE_2020S001083',\n",
       " 'NEXPEDIENTE_2020S001084',\n",
       " 'NEXPEDIENTE_2020S001085',\n",
       " 'NEXPEDIENTE_2020S001086',\n",
       " 'NEXPEDIENTE_2020S001087',\n",
       " 'NEXPEDIENTE_2020S001088',\n",
       " 'NEXPEDIENTE_2020S001089',\n",
       " 'NEXPEDIENTE_2020S001090',\n",
       " 'NEXPEDIENTE_2020S001091',\n",
       " 'NEXPEDIENTE_2020S001094',\n",
       " 'NEXPEDIENTE_2020S001095',\n",
       " 'NEXPEDIENTE_2020S001098',\n",
       " 'NEXPEDIENTE_2020S001100',\n",
       " 'NEXPEDIENTE_2020S001116',\n",
       " 'NEXPEDIENTE_2020S001202',\n",
       " 'NEXPEDIENTE_2020S001220',\n",
       " 'NEXPEDIENTE_2020S001221',\n",
       " 'NEXPEDIENTE_2020S001222',\n",
       " 'NEXPEDIENTE_2020S001223',\n",
       " 'NEXPEDIENTE_2020S001225',\n",
       " 'NEXPEDIENTE_2020S001228',\n",
       " 'NEXPEDIENTE_2020S001230',\n",
       " 'NEXPEDIENTE_2020S001231',\n",
       " 'NEXPEDIENTE_2020S001232',\n",
       " 'NEXPEDIENTE_2020S001233',\n",
       " 'NEXPEDIENTE_2020S001234',\n",
       " 'NEXPEDIENTE_2020S001236',\n",
       " 'NEXPEDIENTE_2020S001237',\n",
       " 'NEXPEDIENTE_2020S001238',\n",
       " 'NEXPEDIENTE_2020S001239',\n",
       " 'NEXPEDIENTE_2020S001240',\n",
       " 'NEXPEDIENTE_2020S001241',\n",
       " 'NEXPEDIENTE_2020S001243',\n",
       " 'NEXPEDIENTE_2020S001244',\n",
       " 'NEXPEDIENTE_2020S001245',\n",
       " 'NEXPEDIENTE_2020S001247',\n",
       " 'NEXPEDIENTE_2020S001248',\n",
       " 'NEXPEDIENTE_2020S001250',\n",
       " 'NEXPEDIENTE_2020S001251',\n",
       " 'NEXPEDIENTE_2020S001253',\n",
       " 'NEXPEDIENTE_2020S001254',\n",
       " 'NEXPEDIENTE_2020S001255',\n",
       " 'NEXPEDIENTE_2020S001257',\n",
       " 'NEXPEDIENTE_2020S001258',\n",
       " 'NEXPEDIENTE_2020S001259',\n",
       " 'NEXPEDIENTE_2020S001261',\n",
       " 'NEXPEDIENTE_2020S001262',\n",
       " 'NEXPEDIENTE_2020S001263',\n",
       " 'NEXPEDIENTE_2020S001264',\n",
       " 'NEXPEDIENTE_2020S001265',\n",
       " 'NEXPEDIENTE_2020S001266',\n",
       " 'NEXPEDIENTE_2020S001268',\n",
       " 'NEXPEDIENTE_2020S001269',\n",
       " 'NEXPEDIENTE_2020S001270',\n",
       " 'NEXPEDIENTE_2020S001271',\n",
       " 'NEXPEDIENTE_2020S001272',\n",
       " 'NEXPEDIENTE_2020S001273',\n",
       " 'NEXPEDIENTE_2020S001276',\n",
       " 'NEXPEDIENTE_2020S001277',\n",
       " 'NEXPEDIENTE_2020S001278',\n",
       " 'NEXPEDIENTE_2020S001280',\n",
       " 'NEXPEDIENTE_2020S001281',\n",
       " 'NEXPEDIENTE_2020S001282',\n",
       " 'NEXPEDIENTE_2020S001285',\n",
       " 'NEXPEDIENTE_2020S001287',\n",
       " 'NEXPEDIENTE_2020S001288',\n",
       " 'NEXPEDIENTE_2020S001289',\n",
       " 'NEXPEDIENTE_2020S001290',\n",
       " 'NEXPEDIENTE_2020S001291',\n",
       " 'NEXPEDIENTE_2020S001292',\n",
       " 'NEXPEDIENTE_2020S001293',\n",
       " 'NEXPEDIENTE_2020S001294',\n",
       " 'NEXPEDIENTE_2020S001295',\n",
       " 'NEXPEDIENTE_2020S001296',\n",
       " 'NEXPEDIENTE_2020S001297',\n",
       " 'NEXPEDIENTE_2020S001298',\n",
       " 'NEXPEDIENTE_2020S001300',\n",
       " 'NEXPEDIENTE_2020S001302',\n",
       " 'NEXPEDIENTE_2020S001303',\n",
       " 'NEXPEDIENTE_2020S001305',\n",
       " 'NEXPEDIENTE_2020S001311',\n",
       " 'NEXPEDIENTE_2020S001313',\n",
       " 'NEXPEDIENTE_2020S001315',\n",
       " 'NEXPEDIENTE_2020S001317',\n",
       " 'NEXPEDIENTE_2020S001319',\n",
       " 'NEXPEDIENTE_2020S001323',\n",
       " 'NEXPEDIENTE_2020S001324',\n",
       " 'NEXPEDIENTE_2020S001325',\n",
       " 'NEXPEDIENTE_2020S001328',\n",
       " 'NEXPEDIENTE_2020S001329',\n",
       " 'NEXPEDIENTE_2020S001330',\n",
       " 'NEXPEDIENTE_2020S001331',\n",
       " 'NEXPEDIENTE_2020S001332',\n",
       " 'NEXPEDIENTE_2020S001334',\n",
       " 'NEXPEDIENTE_2020S001335',\n",
       " 'NEXPEDIENTE_2020S001337',\n",
       " 'NEXPEDIENTE_2020S001338',\n",
       " 'NEXPEDIENTE_2020S001339',\n",
       " 'NEXPEDIENTE_2020S001340',\n",
       " 'NEXPEDIENTE_2020S001341',\n",
       " 'NEXPEDIENTE_2020S001343',\n",
       " 'NEXPEDIENTE_2020S001345',\n",
       " 'NEXPEDIENTE_2020S001347',\n",
       " 'NEXPEDIENTE_2020S001348',\n",
       " 'NEXPEDIENTE_2020S001349',\n",
       " 'NEXPEDIENTE_2020S001350',\n",
       " 'NEXPEDIENTE_2020S001351',\n",
       " 'NEXPEDIENTE_2020S001352',\n",
       " 'NEXPEDIENTE_2020S001354',\n",
       " 'NEXPEDIENTE_2020S001355',\n",
       " 'NEXPEDIENTE_2020S001356',\n",
       " 'NEXPEDIENTE_2020S001358',\n",
       " 'NEXPEDIENTE_2020S001359',\n",
       " 'NEXPEDIENTE_2020S001360',\n",
       " 'NEXPEDIENTE_2020S001361',\n",
       " 'NEXPEDIENTE_2020S001362',\n",
       " 'NEXPEDIENTE_2020S001363',\n",
       " 'NEXPEDIENTE_2020S001364',\n",
       " 'NEXPEDIENTE_2020S001366',\n",
       " 'NEXPEDIENTE_2020S001367',\n",
       " 'NEXPEDIENTE_2020S001368',\n",
       " 'NEXPEDIENTE_2020S001370',\n",
       " 'NEXPEDIENTE_2020S001371',\n",
       " 'NEXPEDIENTE_2020S001372',\n",
       " 'NEXPEDIENTE_2020S001373',\n",
       " 'NEXPEDIENTE_2020S001374',\n",
       " 'NEXPEDIENTE_2020S001375',\n",
       " 'NEXPEDIENTE_2020S001376',\n",
       " 'NEXPEDIENTE_2020S001377',\n",
       " 'NEXPEDIENTE_2020S001378',\n",
       " 'NEXPEDIENTE_2020S001379',\n",
       " 'NEXPEDIENTE_2020S001381',\n",
       " 'NEXPEDIENTE_2020S001382',\n",
       " 'NEXPEDIENTE_2020S001383',\n",
       " 'NEXPEDIENTE_2020S001384',\n",
       " 'NEXPEDIENTE_2020S001385',\n",
       " 'NEXPEDIENTE_2020S001386',\n",
       " 'NEXPEDIENTE_2020S001387',\n",
       " 'NEXPEDIENTE_2020S001388',\n",
       " 'NEXPEDIENTE_2020S001389',\n",
       " 'NEXPEDIENTE_2020S001390',\n",
       " 'NEXPEDIENTE_2020S001392',\n",
       " 'NEXPEDIENTE_2020S001393',\n",
       " 'NEXPEDIENTE_2020S001395',\n",
       " 'NEXPEDIENTE_2020S001398',\n",
       " 'NEXPEDIENTE_2020S001400',\n",
       " 'NEXPEDIENTE_2020S001402',\n",
       " 'NEXPEDIENTE_2020S001404',\n",
       " 'NEXPEDIENTE_2020S001405',\n",
       " 'NEXPEDIENTE_2020S001407',\n",
       " 'NEXPEDIENTE_2020S001408',\n",
       " 'NEXPEDIENTE_2020S001410',\n",
       " 'NEXPEDIENTE_2020S001411',\n",
       " 'NEXPEDIENTE_2020S001412',\n",
       " 'NEXPEDIENTE_2020S001413',\n",
       " 'NEXPEDIENTE_2020S001414',\n",
       " 'NEXPEDIENTE_2020S001415',\n",
       " 'NEXPEDIENTE_2020S001417',\n",
       " 'NEXPEDIENTE_2020S001418',\n",
       " 'NEXPEDIENTE_2020S001419',\n",
       " 'NEXPEDIENTE_2020S001420',\n",
       " 'NEXPEDIENTE_2020S001421',\n",
       " 'NEXPEDIENTE_2020S001422',\n",
       " 'NEXPEDIENTE_2020S001423',\n",
       " 'NEXPEDIENTE_2020S001424',\n",
       " 'NEXPEDIENTE_2020S001425',\n",
       " 'NEXPEDIENTE_2020S001426',\n",
       " 'NEXPEDIENTE_2020S001427',\n",
       " 'NEXPEDIENTE_2020S001428',\n",
       " 'NEXPEDIENTE_2020S001429',\n",
       " 'NEXPEDIENTE_2020S001430',\n",
       " 'NEXPEDIENTE_2020S001431',\n",
       " 'NEXPEDIENTE_2020S001432',\n",
       " 'NEXPEDIENTE_2020S001433',\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(n_lista_sin)\n",
    "# y ahora añadimos los que se han creado con el one_hot\n",
    "for ele in columnas:\n",
    "    n_lista_sin.append(ele)\n",
    "n_lista_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Hacer la función fillML para cada columna con nulos en ese orden.\n",
    "def fill_ML(df, objetivo, tipo='regresion'):\n",
    "    \"\"\"\n",
    "    df es un dataframe que tiene las columnas sin nulos + la columna objetivo\n",
    "    objetivo es la columna a resolver los nulos\n",
    "    tipo es...\n",
    "    \"\"\"\n",
    "    \n",
    "    df_sin_nulos = df.drop(df[df[objetivo].isnull()].index, axis=0)\n",
    "    df_con_nulos = df.drop(df_sin_nulos.index,axis=0)\n",
    "\n",
    "    y = df_sin_nulos[objetivo]\n",
    "    X = df_sin_nulos.drop([objetivo],axis=1)\n",
    "            \n",
    "    if tipo.lower() == 'regresion':\n",
    "        modelo = ExtraTreesRegressor(n_estimators=250, random_state=0)\n",
    "    elif tipo.lower() == 'clasificacion':\n",
    "        modelo = ExtraTreesClassifier(n_estimators=250, random_state=0)\n",
    "    \n",
    "    modelo.fit(X, y)\n",
    "\n",
    "    X_con = df_con_nulos.drop([objetivo],axis=1)\n",
    "    \n",
    "    if tipo.lower() == 'regresion':\n",
    "        Prediccion = np.round(modelo.predict(X_con))\n",
    "    elif tipo.lower() == 'clasificacion':\n",
    "        Prediccion = modelo.predict(X_con)\n",
    "    return Prediccion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUMERO', 'DISTRITO', 'TIPO PERSONA', 'TIPO ACCIDENTE', 'TIPO VEHICULO', 'TIEMPO', 'SEXO', 'RANGO DE EDAD']\n"
     ]
    }
   ],
   "source": [
    "print(n_lista_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando  NUMERO  con operacion  clasificacion\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '-'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-dd177e8f510c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ML\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# realizamos el fill_ML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobjetivo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjetivo\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_ML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjetivo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperacion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;31m# pasamos objetivo a la lista de columnas sin nulos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mobjetivo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcategoricas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-6ab1cf48ce8d>\u001b[0m in \u001b[0;36mfill_ML\u001b[1;34m(df, objetivo, tipo)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmodelo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mX_con\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_con_nulos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobjetivo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[0;32m    304\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[1;32m--> 305\u001b[1;33m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    876\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    879\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32mc:\\users\\jose\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '-'"
     ]
    }
   ],
   "source": [
    "# hacemos el proceso de ML para todas las columnas que aún tengan nulos.\n",
    "\n",
    "for objetivo in ['NUMERO','DISTRITO']:\n",
    "    if objetivo in numericas:\n",
    "        operacion = \"regresion\"\n",
    "    elif objetivo in categoricas:\n",
    "        operacion = \"clasificacion\"\n",
    "    else:\n",
    "        continue\n",
    "    print(\"Procesando \",objetivo,\" con operacion \", operacion)\n",
    "    # creamos el dataframe\n",
    "    lis = []\n",
    "    lis.append(objetivo)\n",
    "    for e in n_lista_sin:\n",
    "        lis.append(e)\n",
    "    df1 = df_ML[lis]\n",
    "    # realizamos el fill_ML\n",
    "    df.loc[df[objetivo].isnull(), objetivo] = fill_ML(df1, objetivo, operacion)\n",
    "    # pasamos objetivo a la lista de columnas sin nulos\n",
    "    if objetivo in categoricas:\n",
    "        # hay que pasarla primero a one_hot\n",
    "        df_one = pd.get_dummies(data=df_ML[objetivo], columns=objetivo)\n",
    "        columnas = df_one.columns\n",
    "        # y ahora primero las pasamos al df\n",
    "        df_ML = df_ML.drop([objetivo],axis=1)\n",
    "        df_ML =pd.concat([df_ML,df_one],axis=1)\n",
    "    # vamos añadiendo todas las columnas one_hot que hayan salido\n",
    "    for col in columnas:\n",
    "        n_lista_sin.append(col)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Tratamiento de outliers\n",
    "\n",
    "Solo es recomendable si en verdad esos outliers son producto del error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando Gaussian\n",
    "for colu in numericas:\n",
    "    respuesta = input(\"¿Corregimos los outliers de la columna \",colu,\"(S/N)?\")\n",
    "    if respuesta.lower()==\"s\":\n",
    "        df.loc[df[colu] > Ug, colu] = Ug\n",
    "        df.loc[df[colu] < Lg, colu] = Lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando Interquantil 1.5\n",
    "for colu in numericas:\n",
    "    respuesta = input(\"¿Corregimos los outliers de la columna \",colu,\"(S/N)?\")\n",
    "    if respuesta.lower()==\"s\":\n",
    "        df.loc[df[colu] > U15, colu] = U15\n",
    "        df.loc[df[colu] < L15, colu] = L15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando Interquantil 3.0\n",
    "for colu in numericas:\n",
    "    respuesta = input(\"¿Corregimos los outliers de la columna \",colu,\"(S/N)?\")\n",
    "    if respuesta.lower()==\"s\":\n",
    "        df.loc[df[colu] > U30, colu] = U30\n",
    "        df.loc[df[colu] < L30, colu] = L30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Agrupamiento de categorias con pocas filas asociadas (raros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto depende de cada dataset. Por ello que nos basaremos en lo que se ha sacado en el 4.4\n",
    "# Sin embargo el siguiente código puede ayudar\n",
    "\n",
    "# Primero vamos a ver qué tal de frecuentes son los valores en las distintas variables categóricas\n",
    "total = len(df)\n",
    "\n",
    "for col in categoricas:\n",
    "    # contamos las filas por etiqueta y dividimos por el total \n",
    "    temp_df = pd.Series(df[col].value_counts() / total)\n",
    "    # renombramos las columnas\n",
    "    temp_df.columns = [col, col + '_perc_raro']\n",
    "    # hacemos un gráfico\n",
    "    fig = temp_df.sort_values(ascending=False).plot.bar()\n",
    "    fig.set_xlabel(col)\n",
    "    fig.set_ylabel('porcentaje sobre el total')\n",
    "    plt.show()\n",
    "    \n",
    "# Ordenamos para ver quien son más raros y quien menos\n",
    "temp_df.sort_values(ascending=False)\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este limite nos va a servir para determinar qué porcentaje (de 0 a 1) es considerado raro.\n",
    "limite = 0.2\n",
    "# Mostramos aquellas características que están por encima del límite. \"Las NO raras\"\n",
    "temp_df[temp_df >= limite].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un diccionario para reemplazar las etiquetas raras, con la cadena \"rara\"\n",
    "grouping_dict = {\n",
    "    k: ('otros' if k not in temp_df[temp_df >= limite].index else k) for k in temp_df.index\n",
    "}\n",
    "# y el resultado es:\n",
    "grouping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazammos las categorías necesarias\n",
    "for col in ['Embarked']:\n",
    "#for col in categoricas:\n",
    "    df[col+'_grouped'] = df[col].map(grouping_dict)\n",
    "    df[[col, col+'_grouped']].head(10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Survived_grouped\",\"Pclass_grouped\",\"Sex_grouped\",\"Ticket_grouped\",\"Cabin_grouped\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Análisis y corrección de distribuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la función que dibuja el histograma y el Q-Q plot a la vez para una cierta columna\n",
    "def diagnostic_plots(df, variable):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    df[variable].hist()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=pylab)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos histograma y Q-Q plot de las columnas numéricas que elijamos\n",
    "correcto = False\n",
    "while not(correcto):\n",
    "    print(numericas)\n",
    "    columna = input(\"Nombre de columna a estudiar y modificar su distribución:\")\n",
    "    if columna in numericas:\n",
    "        correcto=True\n",
    "        diagnostic_plots(df, columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora que ya vemos como está, pasamos a corregir las que no nos gusten\n",
    "# se elige la que más nos guste\n",
    "# creamos una copia para evitar añadir al df si no queremos\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columna = \"Age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformación Logaritmica\n",
    "df2[columna+'_log'] = np.log(df[columna])\n",
    "diagnostic_plots(df2, columna+'_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reciproca\n",
    "df2[columna+'_reciprocal'] = 1 / df[columna]\n",
    "diagnostic_plots(df2, columna+'_reciprocal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformacion de raiz cuadrada\n",
    "df2[columna+'_sqr']  =df[columna]**(1/2)\n",
    "diagnostic_plots(df2, columna+'_sqr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aurea\n",
    "df2[columna+'_aur']  = df[columna]**(1/1.6)\n",
    "diagnostic_plots(df2, columna+'_aur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponencial\n",
    "df2[columna+'_exp']  = df[columna]**(1/1.2)\n",
    "diagnostic_plots(df2, columna+'_exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxcox\n",
    "df2[columna+'_boxcox'], param = stats.boxcox(df[columna]) # ponemos la , porque da dos resultados\n",
    "print('Optimal λ: ', param)\n",
    "diagnostic_plots(df2, columna+'_boxcox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una vez elegida la transformación, basta copiarla sin el df2,\n",
    "# por ejemplo si hemos escogido la áurea\n",
    "# aurea\n",
    "df[columna+'_aur']  = df[columna]**(1/1.6)\n",
    "diagnostic_plots(df, columna+'_aur')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Correlaciones multivariable (numéricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este punto, sólo podemos hacerlo con las columnas numéricas\n",
    "df2=df[numericas]\n",
    "# aplicamos\n",
    "correlation_matrix = df2.corr().round(2)\n",
    "# recordar que podemos introducir parámetros en la función .corr\n",
    "# .corr(method='pearson', min_periods=1)*\n",
    "# - method: aparte de pearson, puede ser además, kendall o spearman\n",
    "# - min_periods: indica el número de periodos para que se considere una observación como válida\n",
    "\n",
    "# annot=True te pone el valor de la correlacion\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Seleccion de características / reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por ahora, podemos usar el Feature Importances para eliminar las columnas que no nos aporte nada\n",
    "# o bien la correlación multivariable para eliminar una de cada dos columna correlacionadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 Ingeniería de características\n",
    "\n",
    "Este apartado está muy ligado a los datos, por lo que se rellenará con lo que se estime en cada dataset. Sólo se presentan ciertos apartados para ser trabajados si son necesarios.\n",
    "\n",
    "#### - Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Agregaciones varias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tic= df.groupby('Ticket')['Ticket'].count().rename_axis('tipo').reset_index()\n",
    "df = pd.merge(df,df_tic,left_on='Ticket',right_on='tipo')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Ticket_x','tipo','Embarked'],axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin']=df['Cabin'].str.replace(\"F G\",\"G\")\n",
    "df['Cabin']=df['Cabin'].str[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Label encoding dirigido a resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay que alinear todos los laben encoding\n",
    "# df['tipoCarretera'] --> ['local','provincial','autonomica','nacional','autovia','autopista','autovia3']\n",
    "#                             6   ,    5       ,     4      ,    3     ,    2    ,     1     ,     0\n",
    "\n",
    "df['Survived'] = df['Survived'].replace(to_replace=[\"S\", \"N\"], value=[1,0])\n",
    "df['Sex'] = df['Sex'].replace(to_replace=[\"female\", \"male\"], value=[1,0])\n",
    "df['Embarked_grouped']= df['Embarked_grouped'].replace(to_replace=[\"S\", \"otros\"], value=[1,0])\n",
    "df['Pclass'] = df['Pclass'].replace(to_replace=[1,2,3], value=[3,2,1])\n",
    "# también cabin se podria y tal vez sea mejor idea con One-Hot\n",
    "df['Cabin'] = df['Cabin'].replace(to_replace=['T','A','B','C','D','E','F','G'], value=[6,6,5,4,3,2,1,0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Creación de columnas que indican existencia de nulos o valores raros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podríamos crear una columna que nos dijese si existía\n",
    "df['existeCabin']=df['Cabin'].apply(lambda x: 0 if x==np.nan else 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Expansión polinómica (Estricta / No estricta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']=df['Age']**2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Eliminación de columnas definitivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.11 Conversión categóricas a numéricas\n",
    "\n",
    "#### - Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También esto está muy relacionado con los datos\n",
    "# Ejemplos:\n",
    "# data['Gender'] = data['Gender'].replace(to_replace=['Male', 'Female'], value=[0,1])\n",
    "# data['Married'] = data['Married'].replace(to_replace=['No', 'Yes'], value=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí aplicaremos one_hot definitivo a las columnas que hayan sobrevivido\n",
    "# df = pd.get_dummies(data=df, columns=categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.12 Separar Target de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellenar target con el nombre de la columna objetivo\n",
    "target=\"Survived\"\n",
    "y = df[target]\n",
    "X = df.drop([target],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.13 Volver a aplicar Correlaciones y Feature Importances (sin estandarizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicamos a todo el dataset ya que en este punto, todo será numérico\n",
    "correlation_matrix = df.corr().round(2)\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se eliminarían columnas \"no productivas\" si son demasiadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "def F_importances(X,y):\n",
    "    # Construye un arbol para así conocer la importancia de las columnas\n",
    "    forest = ExtraTreesRegressor(n_estimators=250, random_state=0)\n",
    "    columnas = X.columns.to_list()\n",
    "    forest.fit(X, y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %s (%f)\" % (f + 1, columnas[indices[f]], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "\n",
    "F_importances(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.14 Aplicar Estandarización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pclass']=df['Pclass'].astype(np.int64)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estandarizar(dataframe):\n",
    "    media = dataframe.mean()\n",
    "    desviacion_estandar = dataframe.std()\n",
    "    return (dataframe - media)/desviacion_estandar\n",
    "\n",
    "X = estandarizar(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.15 (Opcional) Aplicar Feature Importances (con estandarizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se eliminarían columnas \"no productivas\" si son demasiadas\n",
    "F_importances(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya tendríamos nuestro dataset totalmente listo para la siguiente fase\n",
    "df_guardar = pd.concat([X,y],axis=1)\n",
    "df_guardar.to_csv(\"titanic_listo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Opcional) Un vistazo a cómo se comportaría el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos algunas librerías de algortimos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para mayor información sobre train_test_split\n",
    "# train_test_split( * matrices , test_size = None , train_size = None , random_state = None , shuffle = True , stratify = None )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, # los datos (features) nuestra X\n",
    "    y,  # columna objetivo, nuestra y\n",
    "    test_size=0.2,  # el 70% de las filas serán para entrenar y el 30% para probar si ha ido bien\n",
    "    stratify= y,\n",
    "    random_state=0) \n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí deshabilitamos el modelo que necesitemos\n",
    "modelo = LogisticRegression()\n",
    "# modelo = AdaBoostClassifier(n_estimators=200, random_state=44)\n",
    "# modelo = RandomForestClassifier(n_estimators=200, random_state=39)\n",
    "\n",
    "# Entrenamos modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# predicción sobre el conjunto de test\n",
    "pred = modelo.predict_proba(X_test)\n",
    "\n",
    "# calculamos su acierto\n",
    "print('LogReg Accuracy: {}'.format(modelo.score(X_test, y_test)))\n",
    "print('LogReg roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasos para hacer ML con Algoritmos tradicionales:\n",
    "\n",
    "1. Importar de sklearn los algoritmos, herramientas y métricas que necesitéis\n",
    "\n",
    "2. Dividir los datos en conjunto de entrenamiento y el conjunto de test\n",
    "\n",
    "3. Crear una instancia del algoritmo a utilizar (modelo)\n",
    "\n",
    "4. Se entrena ese modelo (.fit) con los datos del conjunto de entrenamiento\n",
    "\n",
    "5. Se evalua con los datos del conjunto de test el rendimiento del modelo (.score)\n",
    "\n",
    "6. Si lo vemos adecuado ya podemos predecir datos nuevos\n",
    "\n",
    "7. Guardar el modelo con pickle si es necesario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasos para saber también cual es el mejor algoritmo a utilizar.\n",
    "\n",
    "1. Importar de sklearn los algoritmos, herramientas y métricas que necesitéis\n",
    "\n",
    "2. Dividir los datos en conjunto de entrenamiento y el conjunto de test\n",
    "\n",
    "    3.1 Hacer una lista de los algoritmos a probar con CrossValidation\n",
    "\n",
    "    3.2 Ejecutar CrossValidation con cada de unos\n",
    "\n",
    "    3.3 Ordenarlos por evaluación de resultados\n",
    "\n",
    "    3.4 Elegir el que mejor se comporte con nuestros datos\n",
    "\n",
    "    3.5 Crear una instancia del algoritmo a utilizar (modelo)\n",
    "\n",
    "4. Se entrena ese modelo (.fit) con los datos del conjunto de entrenamiento\n",
    "\n",
    "5. Se evalua con los datos del conjunto de test el rendimiento del modelo (.score)\n",
    "\n",
    "6. Si lo vemos adecuado ya podemos predecir datos nuevos\n",
    "\n",
    "7. Guardar el modelo con pickle si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
