{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervivencia Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Orígen de datos: https://www.kaggle.com/c/titanic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./titanic.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar datos\n",
    "- Descargar datos a utilizar desde la web\n",
    "- Guardar los datos para que queden disponibles\n",
    "- Importar los ficheros .csv con los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar datos a utilizar desde la web\n",
    "# url_train = \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/train.csv?GoogleAccessId=competitions-data@kaggle-161607.iam.gserviceaccount.com&Expires=1504325799&Signature=ZREfojvjBxGz2%2FF4Yu1Kka3j%2BylZLrFiNNgzVOjRJk4XOpKFgV%2BK4eM0fS874l3fXVvg051nUB%2BDsCVORI%2FN3Cgt%2FyE5OLE5zpwpe%2Ff1zWD5JPS91S767g0oRCT%2FEwqfV4Dx2TwIT1dEZXVBfLVL5qlp5lIDJSOnfezs3at%2BhMpGDJUIKzbtnbA%2BLn%2FhRbtZqa%2B8SnhdmwnDOSkxA9ZYDK9QpmITb7liBRgd3DthiTNCp2ajG%2FSwnOgV8Tm%2FNefDKTMtbRgljgMzvpuQ031SomV5iBu8WmIygqxjfib6DhKP4m5t%2FahZzBYIEfY7AmBokiZDNlwtVwOivWDANIXBzA%3D%3D\"\n",
    "# url_test = \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv?GoogleAccessId=competitions-data@kaggle-161607.iam.gserviceaccount.com&Expires=1504325924&Signature=hL1wMTmPKV5OYjZqHckFPzc%2BWAbEp0dD4AtzxgaLQXosZaj4dtGlM2PEl0Jq0WNTAZhUIQifGweKJM6qTa8G%2FQgRyRunN%2BQa2hqocGDsQ77wi71CkmOvqKogZL0fMLnU%2Bowd7ww5OBSerpAYXY%2FC8vT5J%2BrVfMAxfXQfyO9w1as%2BV7zUia14TfplOxMJwJQGNib08T8qIpZYjyvSZZcWEvoIKPqpnZBqDqnrxGOOvm%2BDpvWL04ftIg7mIAFOlhxiJ87X%2BQOAHyv9u9HBia2lbjn6h%2BoI8HmF0o6i%2BZs6BK3EyMMEEaE1G5dv02j%2B8%2B%2F9V%2FWukLam2y%2Fx1jMs6D3wKQ%3D%3D\"\n",
    "# df_train = pd.read_csv(url_train)\n",
    "# df_test = pd.read_csv(url_test)\n",
    "\n",
    "# Guardar los datos para que queden disponibles siempre\n",
    "# dir_train = 'C:/DS/_Portfolio/Python/Titanic_Clasificacion/titanic_train.csv'\n",
    "# dir_test = 'C:/DS/_Portfolio/Python/Titanic_Clasificacion/titanic_test.csv'\n",
    "# df_train.to_csv(dir_train)\n",
    "# df_test.to_csv(dir_test)\n",
    "\n",
    "# Importar fichero .csv con los datos\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualicemos el contenido de ambos ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Podemos comprobar que ambos datasets contienen los mismos datos. El set de entrenamiento tiene una columna más, que indica si el pasajero sobrevivió o no. Con ésta información, podemos deducir que necesitaremos aplicar **algoritmos supervisados.** ya que para el entrenamiento dispongo de datos donde conozco el resultado.\n",
    " \n",
    " Además, nos damos cuenta de que faltan muchos datos en ambos set, por lo que será necesario realizar un pre-procesamiento de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendiendo la información contenida en los datos\n",
    "Muy útil para hacer el pre-procesamiento de los datos y los algoritmos que tendremos que aplicar.\n",
    "\n",
    "- Verifico la cantidad de datos en ambos datasets\n",
    "- Verifico el tipo de datos\n",
    "- Verifico los datos faltantes\n",
    "- Verifico las estadísticas de ambos datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en el dataset de entrenamiento hay 891 registros con 12 columnas. En el de test, 418 registros y 11 columnas. Deducimos que el set de prueba tiene una columna menos ya que no indica si el pasajero sobrevivió o no. También deducimos que tenemos suficientes datos para entrenar nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 66.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 27.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ambos datasets tenemos tipos de datos numericos, flotantes y objetos. La columna Sex es de tipo objeto y lo tendremos que cambiar para poder utilizarla en los algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobamos datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df_train).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass                      Name     Sex   Age  \\\n",
      "0            1         0       3   Braund, Mr. Owen Harris    male  22.0   \n",
      "2            3         1       3    Heikkinen, Miss. Laina  female  26.0   \n",
      "4            5         0       3  Allen, Mr. William Henry    male  35.0   \n",
      "\n",
      "   SibSp  Parch            Ticket   Fare Cabin Embarked  \n",
      "0      1      0         A/5 21171  7.250   NaN        S  \n",
      "2      0      0  STON/O2. 3101282  7.925   NaN        S  \n",
      "4      0      0            373450  8.050   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "filas_con_nulos = df_train.head().isnull().any(axis=1)\n",
    "print(df_train.head()[filas_con_nulos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "0              1         0       3                   Braund, Mr. Owen Harris   \n",
      "2              3         1       3                    Heikkinen, Miss. Laina   \n",
      "4              5         0       3                  Allen, Mr. William Henry   \n",
      "5              6         0       3                          Moran, Mr. James   \n",
      "7              8         0       3            Palsson, Master. Gosta Leonard   \n",
      "..           ...       ...     ...                                       ...   \n",
      "884          885         0       3                    Sutehall, Mr. Henry Jr   \n",
      "885          886         0       3      Rice, Mrs. William (Margaret Norton)   \n",
      "886          887         0       2                     Montvila, Rev. Juozas   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0      male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
      "2    female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "4      male  35.0      0      0            373450   8.0500   NaN        S  \n",
      "5      male   NaN      0      0            330877   8.4583   NaN        Q  \n",
      "7      male   2.0      3      1            349909  21.0750   NaN        S  \n",
      "..      ...   ...    ...    ...               ...      ...   ...      ...  \n",
      "884    male  25.0      0      0   SOTON/OQ 392076   7.0500   NaN        S  \n",
      "885  female  39.0      0      5            382652  29.1250   NaN        Q  \n",
      "886    male  27.0      0      0            211536  13.0000   NaN        S  \n",
      "888  female   NaN      1      2        W./C. 6607  23.4500   NaN        S  \n",
      "890    male  32.0      0      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[687 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "nan_rows = df_train[df_train['Cabin'].isna()]\n",
    "print(nan_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cabin                                      Name            Ticket\n",
      "0     NaN                   Braund, Mr. Owen Harris         A/5 21171\n",
      "2     NaN                    Heikkinen, Miss. Laina  STON/O2. 3101282\n",
      "4     NaN                  Allen, Mr. William Henry            373450\n",
      "5     NaN                          Moran, Mr. James            330877\n",
      "7     NaN            Palsson, Master. Gosta Leonard            349909\n",
      "..    ...                                       ...               ...\n",
      "884   NaN                    Sutehall, Mr. Henry Jr   SOTON/OQ 392076\n",
      "885   NaN      Rice, Mrs. William (Margaret Norton)            382652\n",
      "886   NaN                     Montvila, Rev. Juozas            211536\n",
      "888   NaN  Johnston, Miss. Catherine Helen \"Carrie\"        W./C. 6607\n",
      "890   NaN                       Dooley, Mr. Patrick            370376\n",
      "\n",
      "[687 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar solo algunas columnas de las filas con 'Cabin' nulo\n",
    "columnas_interes = ['Cabin', 'Name', 'Ticket']  # Cambia esto por las columnas que te interesan\n",
    "nan_rows = df_train[df_train['Cabin'].isna()][columnas_interes]\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama la atención la gran cantidad de datos faltantes en las columnas Age y Cabin. Cabin no afecta mucho al análisis. Age si es relevante. En el pre-rpocesamiento de datos, depuraremos ambos datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas de cada dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media y la desviación estandard en ambos datasets son razonables. Podemos asumir que cualquier relación que encontremos en los datos de entrenamiento debería funcionar de manera similar en los de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los Datos\n",
    "- Cambio los datos de sexos en numéros\n",
    "- Cambio datos de embarque en números\n",
    "- Reemplazo datos faltantes en la edad por el valor medio de la columna\n",
    "- Creo varios grupos de acuerdo a franjas de edad\n",
    "- Elimino la columna *cabin* ya que tiene muchos valores perdidos\n",
    "- Elimino columnas innecesarias para el análisis\n",
    "- Elimino filas con datos perdidos\n",
    "- Verifico los datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Female -> 0, Male -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sex'].replace(['female', 'male'],[0,1], inplace = True)\n",
    "df_test['Sex'].replace(['female', 'male'],[0,1], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked Q -> 0, S -> 1, C -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Embarked'].replace(['Q', 'S', 'C'], [0, 1, 2], inplace = True)\n",
    "df_test['Embarked'].replace(['Q', 'S', 'C'], [0, 1, 2], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reemplazo datos perdidos por el valor medio de la columna Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.272590361445783"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redondeo ambas medias a 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio = 30\n",
    "df_train['Age'] = df_train['Age'].replace(np.nan, promedio)\n",
    "df_test['Age'] = df_test['Age'].replace(np.nan, promedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>29.758889</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>1.102362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>13.002570</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.515181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642    0.647587   29.758889   \n",
       "std     257.353842    0.486592    0.836071    0.477990   13.002570   \n",
       "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
       "25%     223.500000    0.000000    2.000000    0.000000   22.000000   \n",
       "50%     446.000000    0.000000    3.000000    1.000000   30.000000   \n",
       "75%     668.500000    1.000000    3.000000    1.000000   35.000000   \n",
       "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
       "\n",
       "            SibSp       Parch        Fare    Embarked  \n",
       "count  891.000000  891.000000  891.000000  889.000000  \n",
       "mean     0.523008    0.381594   32.204208    1.102362  \n",
       "std      1.102743    0.806057   49.693429    0.515181  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    7.910400    1.000000  \n",
       "50%      0.000000    0.000000   14.454200    1.000000  \n",
       "75%      1.000000    0.000000   31.000000    1.000000  \n",
       "max      8.000000    6.000000  512.329200    2.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupo las edades en bandas (0-8, 9-15, 16-18, 19-25, 26-40, 41-60, 61-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 8, 15, 18, 25, 40, 60, 100] # rangos\n",
    "names = ['1', '2', '3', '4', '5', '6', '7'] # nombres\n",
    "\n",
    "df_train['Age'] = pd.cut(df_train['Age'], bins, labels = names)\n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins, labels = names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elimino la columna *Cabin* dado que tiene muchos datos perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['Cabin'], axis = 1, inplace = True)\n",
    "df_test.drop(['Cabin'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elimino las columnas innecesarias para el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True)\n",
    "df_test.drop(['Name', 'Ticket'], axis = 1, inplace = True) # No elimino PassengerId porque la utilizaré mas adelante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos las filas con datos perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(axis = 0, how = 'any', inplace = True)\n",
    "df_test.dropna(axis = 0, how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifico los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(df_train).sum())\n",
    "print(pd.isnull(df_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 8)\n",
      "(417, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex Age  SibSp  Parch     Fare  Embarked\n",
      "0         0       3    1   4      1      0   7.2500       1.0\n",
      "1         1       1    0   5      1      0  71.2833       2.0\n",
      "2         1       3    0   5      0      0   7.9250       1.0\n",
      "3         1       1    0   5      1      0  53.1000       1.0\n",
      "4         0       3    1   5      0      0   8.0500       1.0\n",
      "   PassengerId  Pclass  Sex Age  SibSp  Parch     Fare  Embarked\n",
      "0          892       3    1   5      0      0   7.8292         0\n",
      "1          893       3    0   6      1      0   7.0000         1\n",
      "2          894       2    1   7      0      0   9.6875         0\n",
      "3          895       3    1   5      0      0   8.6625         1\n",
      "4          896       3    0   4      1      1  12.2875         1\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de Algoritmos de Machine Learning\n",
    "\n",
    "- Separo columna con la información de los supervivientes\n",
    "- Separo los datos de \"train\" en entrenamiento\n",
    "- Prueba para probar algoritmos:\n",
    " - Regresión Logística\n",
    " - Máquinas de Vector Soporte\n",
    " - K Vecinos más cercanos\n",
    " \n",
    "En ésta etapa utilizaremos los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo la columna supervivientes\n",
    "x = np.array(df_train.drop(['Survived'], 1)) # variables para construir el modelo\n",
    "y = np.array(df_train['Survived']) # resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo los datos del dataset \"train\"\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Regresión Logística: \n",
      "0.810126582278481\n"
     ]
    }
   ],
   "source": [
    "# Regresion Logistica\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "print('Precisión Regresión Logística: ')\n",
    "print(logreg.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Máquinas Vector Soporte: \n",
      "0.680731364275668\n"
     ]
    }
   ],
   "source": [
    "# Máquina Vector Soporte\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "y_pred = svc.predict(x_test)\n",
    "print('Precisión Máquinas Vector Soporte: ')\n",
    "print(svc.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Vecinos más Cercanos: \n",
      "0.8635724331926864\n"
     ]
    }
   ],
   "source": [
    "# Vecinos Mas Cercanos\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print('Precisión Vecinos más Cercanos: ')\n",
    "print(knn.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que el algoritmo más adecuado para realizar las predicciones es **K Vecinos más cercanos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion utilizando los modelos y el dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una columna con los ids de los pasajeros y ver quién sobrevive.\n",
    "ids = df_test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción Regresión Logística: \n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n"
     ]
    }
   ],
   "source": [
    "# Prediccion Regresión Lineal\n",
    "prediccion_logreg = logreg.predict(df_test.drop('PassengerId', axis = 1))\n",
    "out_logreg = pd.DataFrame({'PassengerId':ids, 'Survived': prediccion_logreg})\n",
    "print('Predicción Regresión Logística: ')\n",
    "print(out_logreg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción Máquins Vector Soporte: \n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         0\n"
     ]
    }
   ],
   "source": [
    "# Prediccion Maquinas Vector Soporte\n",
    "prediccion_svc = svc.predict(df_test.drop('PassengerId', axis = 1))\n",
    "out_svc = pd.DataFrame({'PassengerId':ids, 'Survived': prediccion_svc})\n",
    "print('Predicción Máquins Vector Soporte: ')\n",
    "print(out_svc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción Vecinos Más Cercanos: \n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         0\n"
     ]
    }
   ],
   "source": [
    "# Prediccion Vecinos mas Cercanos\n",
    "prediccion_knn = knn.predict(df_test.drop('PassengerId', axis = 1))\n",
    "out_knn = pd.DataFrame({'PassengerId':ids, 'Survived': prediccion_svc})\n",
    "print('Predicción Vecinos Más Cercanos: ')\n",
    "print(out_knn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
